{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233720ae-3e99-4d67-8c73-c94976f4738d",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfa0bc8-87a0-47cc-b7aa-5872cf41cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pylot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "cust_df = pd.read_csv('./train.csv', encoding='latin-1')\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c252be40-6f0e-48fb-af93-c2b4ef8dfc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eef98c2-b3b9-4639-9127-b92db02d7c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    73012\n",
      "1     3008\n",
      "Name: count, dtype: int64\n",
      "unsatisfied비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] ==1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print('unsatisfied비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594822e-eb5c-442e-abd2-4da29bf67dc2",
   "metadata": {},
   "source": [
    "대부분이 만족이며 불만족 비율은 0.04%에 불과하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da9cb525-d791-4a81-b155-b2c09a1f9f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2b23e1-5754-432b-9fae-dd62aa541adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처 데이터 shape:(76020, 369)\n"
     ]
    }
   ],
   "source": [
    "cust_df['var3'].replace(-999999,2,inplace=True)\n",
    "cust_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:,-1]\n",
    "print('피처 데이터 shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499b0686-21e6-440b-8981-fd07c49122d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
      "학습 세트 레이블 값 비율\n",
      "TARGET\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: count, dtype: float64\n",
      "테스트 세트 레이블 비율\n",
      "TARGET\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "print('학습 세트 레이블 값 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('테스트 세트 레이블 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae82d5d-b95c-4f68-8d45-4288c01dc9c1",
   "metadata": {},
   "source": [
    "test_size=0.2 이므로 train데이터 : test데이터는 8대2 비율을 유지한다.  \n",
    "학습 데이터와 테스트 데이터의 TARGET값 분포가 원본과 유사하게 나오도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d4dda2-6ce4-44c8-ae4b-c7ceb61ef34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51492d0-60ff-4d94-bf5a-309a64e8880f",
   "metadata": {},
   "source": [
    "## XGBoost 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b1f6c-efd0-49e6-83e5-1e0be7e55371",
   "metadata": {},
   "source": [
    "### XGBoost 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba47a39-dd6d-474c-a4cd-cf44ee935235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.16022\tvalidation_1-logloss:0.16168\n",
      "[50]\tvalidation_0-logloss:0.12248\tvalidation_1-logloss:0.13510\n",
      "[100]\tvalidation_0-logloss:0.11728\tvalidation_1-logloss:0.13470\n",
      "[150]\tvalidation_0-logloss:0.11459\tvalidation_1-logloss:0.13483\n",
      "[200]\tvalidation_0-logloss:0.11248\tvalidation_1-logloss:0.13503\n",
      "[250]\tvalidation_0-logloss:0.11016\tvalidation_1-logloss:0.13532\n",
      "[300]\tvalidation_0-logloss:0.10767\tvalidation_1-logloss:0.13563\n",
      "[350]\tvalidation_0-logloss:0.10431\tvalidation_1-logloss:0.13602\n",
      "[400]\tvalidation_0-logloss:0.10195\tvalidation_1-logloss:0.13652\n",
      "[450]\tvalidation_0-logloss:0.09927\tvalidation_1-logloss:0.13696\n",
      "[499]\tvalidation_0-logloss:0.09746\tvalidation_1-logloss:0.13739\n",
      "ROC AUC: 0.8385\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156, early_stopping_round=100)\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)], verbose=50)\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score)) # XGBoost ROC AUC: 0.8385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d88ec2-68c9-4613-9bec-fc1e5962b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=500, learning_rate=0.05, random_state=156, early_stopping_round=100 => ROC AUC: 0.8385\n",
    "# n_estimators=700, learning_rate=0.05, random_state=156, early_stopping_round=200 => ROC AUC: 0.8345\n",
    "# n_estimators=500, learning_rate=0.07, random_state=156, early_stopping_round=100 => ROC AUC: 0.8322\n",
    "# n_estimators=900, learning_rate=0.05, random_state=156, early_stopping_round=100 => ROC AUC: 0.8294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369e1dd-a28f-4566-bf50-44e9bbb6d513",
   "metadata": {},
   "source": [
    "### XGBoost의 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19fbf5a-4470-4f56-9ab7-fd312ecf6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.13.1)\n",
      "Requirement already satisfied: six in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (3.3)\n",
      "Requirement already satisfied: future in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (4.66.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (0.10.9.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install hyperopt\n",
    "from hyperopt import hp\n",
    "\n",
    "xgb_search_space = {'max_depth':hp.quniform('max_depth',5,15,1),\n",
    "                    'min_child_weight':hp.quniform('min_child_weight',1,6,1),\n",
    "                    'colsample_bytree':hp.uniform('colsample_bytree',0.5,0.95),\n",
    "                    'learning_rate':hp.uniform('learning_rate',0.01,0.2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed7fe4-df2d-4d99-a799-58e4710d4c6e",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745a05ca-a21b-4b66-a0e5-67db2984be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, \n",
    "                            max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                           early_stopping_rounds=30)\n",
    "\n",
    "    roc_auc_list = []\n",
    "\n",
    "    kf = KFold(n_splits=3)\n",
    "\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        \n",
    "        xgb_clf.fit(X_tr, y_tr,\n",
    "                    eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                    verbose=False)\n",
    "        \n",
    "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    return -1 * np.mean(roc_auc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4dc30d-5b5f-4d9c-bb51-2b557347a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [22:56<00:00, 27.53s/trial, best loss: -0.8387962102037628]\n",
      "best: {'colsample_bytree': 0.7896425601973851, 'learning_rate': 0.10113565387321358, 'max_depth': 5.0, 'min_child_weight': 5.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:',best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "830c2160-0240-4959-a1d8-9dce58e1a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.16002\tvalidation_1-logloss:0.16162\n",
      "[50]\tvalidation_0-logloss:0.12367\tvalidation_1-logloss:0.13433\n",
      "[100]\tvalidation_0-logloss:0.11945\tvalidation_1-logloss:0.13452\n",
      "[144]\tvalidation_0-logloss:0.11641\tvalidation_1-logloss:0.13495\n",
      "ROC AUC: 0.8445\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=round(best['learning_rate'],5),\n",
    "                        max_depth = int(best['max_depth']),\n",
    "                        min_child_weight = int(best['min_child_weight']),\n",
    "                        colsample_bytree=round(best['colsample_bytree'],5),\n",
    "                        early_stopping_rounds=100\n",
    "                       )\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr,\n",
    "            eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "           verbose=50)\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score)) # 하이퍼파라미터 튜닝 ROC AUC: 0.8424"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b6981-55f3-4e15-999f-db59b5019bb0",
   "metadata": {},
   "source": [
    "### 결과\n",
    "XGBoost ROC AUC: 0.8385  \n",
    "하이퍼파라미터 튜닝 ROC AUC: 0.8424  \n",
    "  \n",
    "튜닝 이후 개선되었다.\n",
    "단, XGBoost가 GBM보다는 빠르지만 아무래도 GBM을 기반으로 하기 때문에 수행 시간이 상당히 많이 요구된다.  \n",
    "앙상블 계열 알고리즘에서 하이퍼 파라미터 튜닝으로 성능 수치 개선이 급격히 되는 경우는 많지 않다.  \n",
    "\n",
    "튜닝된 모델에서 각 피처의 중요도를 피처 중요도 그래프로 표현 -> xgboost 모듈의 plot_importance() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183da77e-b798-4a80-8e63-e881524127e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "plot_importance(xgb_clf, ax=ax, max_num_features=20, height=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c95f58-40cb-40fe-9764-25da583f1ca3",
   "metadata": {},
   "source": [
    "XGBoost 예측 성능을 좌우하는 중요 피처 : var38, var15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a712fa9-93a2-42cd-8dfa-2a075fb505c6",
   "metadata": {},
   "source": [
    "## LightGBM 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abebcf-38b4-40c5-bea7-13c3cee0d107",
   "metadata": {},
   "source": [
    "### LightGBM모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee97f6e-6c38-472a-aabe-25332a299eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1658, number of negative: 40913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13308\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 242\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038947 -> initscore=-3.205836\n",
      "[LightGBM] [Info] Start training from score -3.205836\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.112183\tvalid_1's binary_logloss: 0.13527\n",
      "ROC AUC: 0.838429\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100)\n",
    "\n",
    "eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_Score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:4f}'.format(lgbm_roc_Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337adf2-8524-4cd8-b2aa-f58cd97c35cd",
   "metadata": {},
   "source": [
    "### LightGBM의 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f0afb15-f342-4dc1-9f5f-bf9a49819f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves':hp.quniform('num_leaves',32,64,1),\n",
    "                     'max_depth': hp.quniform('max_depth',100,160,1),\n",
    "                    'min_child_samples':hp.quniform('min_child_samples',60,100,1),\n",
    "                    'subsample':hp.uniform('subsample',0.7,1),\n",
    "                    'learning_rate':hp.uniform('learning_rate',0.01,0.2)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93517862-3d51-4483-b837-a0a84c5d077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                              num_leaves=int(search_space['num_leaves']),\n",
    "                              max_depth=int(search_space['max_depth']),\n",
    "                              min_child_samples=int(search_space['min_child_samples']),\n",
    "                              subsample=search_space['subsample'],\n",
    "                              learning_rate=search_space['learning_rate'],\n",
    "                             early_stopping_rounds=30)\n",
    "    roc_auc_list = []\n",
    "    kf = KFold(n_splits=3)\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        \n",
    "        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_val, y_val)])\n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:,1])\n",
    "        roc_auc_list.append(score)\n",
    "    return -1 * np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a22144b-3aba-4264-9196-540379a23a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.121691\tvalid_1's binary_logloss: 0.135854\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.123806\tvalid_1's binary_logloss: 0.13102\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121345\tvalid_1's binary_logloss: 0.136434\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.116101\tvalid_1's binary_logloss: 0.13651\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.115144\tvalid_1's binary_logloss: 0.131217\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.114807\tvalid_1's binary_logloss: 0.137799\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.117842\tvalid_1's binary_logloss: 0.13612\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.116124\tvalid_1's binary_logloss: 0.130594\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.115344\tvalid_1's binary_logloss: 0.136679\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.110829\tvalid_1's binary_logloss: 0.136072\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.108961\tvalid_1's binary_logloss: 0.130846\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.110318\tvalid_1's binary_logloss: 0.137738\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.115347\tvalid_1's binary_logloss: 0.135605\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.115128\tvalid_1's binary_logloss: 0.130766\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.114029\tvalid_1's binary_logloss: 0.136655\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.127637\tvalid_1's binary_logloss: 0.137831\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.129898\tvalid_1's binary_logloss: 0.133066\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.127136\tvalid_1's binary_logloss: 0.138892\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.120387\tvalid_1's binary_logloss: 0.136333\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.118736\tvalid_1's binary_logloss: 0.131262\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's binary_logloss: 0.116468\tvalid_1's binary_logloss: 0.137155\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.115785\tvalid_1's binary_logloss: 0.136488\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.114888\tvalid_1's binary_logloss: 0.131395\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.113891\tvalid_1's binary_logloss: 0.138015\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.119098\tvalid_1's binary_logloss: 0.136082\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.118696\tvalid_1's binary_logloss: 0.131068\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.116749\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.117245\tvalid_1's binary_logloss: 0.136033\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.115521\tvalid_1's binary_logloss: 0.130554\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.116854\tvalid_1's binary_logloss: 0.136736\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.114779\tvalid_1's binary_logloss: 0.136755\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.115313\tvalid_1's binary_logloss: 0.133237\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.112274\tvalid_1's binary_logloss: 0.139062\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.114367\tvalid_1's binary_logloss: 0.136203\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.113074\tvalid_1's binary_logloss: 0.131037\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.111096\tvalid_1's binary_logloss: 0.137228\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.11902\tvalid_1's binary_logloss: 0.136321\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13050\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.11568\tvalid_1's binary_logloss: 0.131373\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.113956\tvalid_1's binary_logloss: 0.137568\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.113833\tvalid_1's binary_logloss: 0.13584\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.113411\tvalid_1's binary_logloss: 0.130684\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.11079\tvalid_1's binary_logloss: 0.13635\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.119835\tvalid_1's binary_logloss: 0.135834\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.117984\tvalid_1's binary_logloss: 0.131018\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.114383\tvalid_1's binary_logloss: 0.136812\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.114433\tvalid_1's binary_logloss: 0.135977\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.112461\tvalid_1's binary_logloss: 0.131242\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.111934\tvalid_1's binary_logloss: 0.137242\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12835\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.120091\tvalid_1's binary_logloss: 0.135824\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.12218\tvalid_1's binary_logloss: 0.13083\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12863\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119522\tvalid_1's binary_logloss: 0.136618\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.116893\tvalid_1's binary_logloss: 0.136357\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.113216\tvalid_1's binary_logloss: 0.13115\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.110917\tvalid_1's binary_logloss: 0.136891\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.114527\tvalid_1's binary_logloss: 0.136277\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.113994\tvalid_1's binary_logloss: 0.131827\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.113791\tvalid_1's binary_logloss: 0.137537\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119715\tvalid_1's binary_logloss: 0.135597\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121795\tvalid_1's binary_logloss: 0.130833\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119143\tvalid_1's binary_logloss: 0.136485\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.115666\tvalid_1's binary_logloss: 0.135727\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's binary_logloss: 0.118088\tvalid_1's binary_logloss: 0.130656\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's binary_logloss: 0.115823\tvalid_1's binary_logloss: 0.136543\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12926\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.115388\tvalid_1's binary_logloss: 0.135942\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.115476\tvalid_1's binary_logloss: 0.130922\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.113368\tvalid_1's binary_logloss: 0.13644\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.128787\tvalid_1's binary_logloss: 0.137803\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.131041\tvalid_1's binary_logloss: 0.133108\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.128267\tvalid_1's binary_logloss: 0.138809\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.117721\tvalid_1's binary_logloss: 0.135749\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.1202\tvalid_1's binary_logloss: 0.130426\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.117598\tvalid_1's binary_logloss: 0.135991\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.118799\tvalid_1's binary_logloss: 0.135841\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.116214\tvalid_1's binary_logloss: 0.13057\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.118269\tvalid_1's binary_logloss: 0.136548\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.120175\tvalid_1's binary_logloss: 0.135615\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119917\tvalid_1's binary_logloss: 0.130481\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.117594\tvalid_1's binary_logloss: 0.135984\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.132023\tvalid_1's binary_logloss: 0.140025\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.134325\tvalid_1's binary_logloss: 0.135128\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.131493\tvalid_1's binary_logloss: 0.141144\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.115089\tvalid_1's binary_logloss: 0.135956\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.115673\tvalid_1's binary_logloss: 0.130635\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.115611\tvalid_1's binary_logloss: 0.13686\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.115813\tvalid_1's binary_logloss: 0.135322\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.117963\tvalid_1's binary_logloss: 0.130349\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.114921\tvalid_1's binary_logloss: 0.136087\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.116619\tvalid_1's binary_logloss: 0.135645\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.117938\tvalid_1's binary_logloss: 0.130448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.117748\tvalid_1's binary_logloss: 0.136235\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.11633\tvalid_1's binary_logloss: 0.135504\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.120421\tvalid_1's binary_logloss: 0.130419\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.115794\tvalid_1's binary_logloss: 0.135859\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.116404\tvalid_1's binary_logloss: 0.135806\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.118006\tvalid_1's binary_logloss: 0.13048\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.114515\tvalid_1's binary_logloss: 0.13597\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.117342\tvalid_1's binary_logloss: 0.135969\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.113141\tvalid_1's binary_logloss: 0.131089\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.115371\tvalid_1's binary_logloss: 0.136859\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.114195\tvalid_1's binary_logloss: 0.136286\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.109021\tvalid_1's binary_logloss: 0.131129\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.113768\tvalid_1's binary_logloss: 0.137725\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.120097\tvalid_1's binary_logloss: 0.135686\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.119396\tvalid_1's binary_logloss: 0.130514\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's binary_logloss: 0.116378\tvalid_1's binary_logloss: 0.1362\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.11705\tvalid_1's binary_logloss: 0.1355\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.117347\tvalid_1's binary_logloss: 0.130237\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.115092\tvalid_1's binary_logloss: 0.136329\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.114995\tvalid_1's binary_logloss: 0.136039\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.11569\tvalid_1's binary_logloss: 0.13063\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.113835\tvalid_1's binary_logloss: 0.13665\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.11721\tvalid_1's binary_logloss: 0.135984\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.114459\tvalid_1's binary_logloss: 0.130701\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.115871\tvalid_1's binary_logloss: 0.136668\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.120348\tvalid_1's binary_logloss: 0.136155\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.119451\tvalid_1's binary_logloss: 0.131012\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.11645\tvalid_1's binary_logloss: 0.136451\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.12009\tvalid_1's binary_logloss: 0.135675\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.118193\tvalid_1's binary_logloss: 0.130602\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.11623\tvalid_1's binary_logloss: 0.136153\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.116738\tvalid_1's binary_logloss: 0.135853\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.117418\tvalid_1's binary_logloss: 0.130448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.113352\tvalid_1's binary_logloss: 0.136288\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.116344\tvalid_1's binary_logloss: 0.136167\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.113436\tvalid_1's binary_logloss: 0.131078\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.113935\tvalid_1's binary_logloss: 0.137141\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.112933\tvalid_1's binary_logloss: 0.136188\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.115172\tvalid_1's binary_logloss: 0.130748\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.114785\tvalid_1's binary_logloss: 0.136832\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.117312\tvalid_1's binary_logloss: 0.135902\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.118173\tvalid_1's binary_logloss: 0.131307\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.115554\tvalid_1's binary_logloss: 0.137295\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121907\tvalid_1's binary_logloss: 0.135965\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.124035\tvalid_1's binary_logloss: 0.131212\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121394\tvalid_1's binary_logloss: 0.136876\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.11663\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.117802\tvalid_1's binary_logloss: 0.131163\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.109973\tvalid_1's binary_logloss: 0.13719\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.119207\tvalid_1's binary_logloss: 0.135473\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.119242\tvalid_1's binary_logloss: 0.130134\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.116569\tvalid_1's binary_logloss: 0.136171\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.114617\tvalid_1's binary_logloss: 0.136351\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.112433\tvalid_1's binary_logloss: 0.131448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.112794\tvalid_1's binary_logloss: 0.137877\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.114476\tvalid_1's binary_logloss: 0.137269\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.117329\tvalid_1's binary_logloss: 0.132223\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.118661\tvalid_1's binary_logloss: 0.138344\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.124109\tvalid_1's binary_logloss: 0.136673\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.126412\tvalid_1's binary_logloss: 0.131761\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.123614\tvalid_1's binary_logloss: 0.137451\n",
      "best: {'learning_rate': 0.07283348800335702, 'max_depth': 133.0, 'min_child_samples': 89.0, 'num_leaves': 32.0, 'subsample': 0.7011491391896255}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, space=lgbm_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(seed=30),\n",
    "            verbose=False)\n",
    "\n",
    "print('best:',best)\n",
    "# best: {'learning_rate': 0.07283348800335702, 'max_depth': 133.0, 'min_child_samples': 89.0, 'num_leaves': 32.0, 'subsample': 0.7011491391896255}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11191b6a-bf42-41b1-9626-b244daf1a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1658, number of negative: 40913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12898\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038947 -> initscore=-3.205836\n",
      "[LightGBM] [Info] Start training from score -3.205836\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.118292\tvalid_1's binary_logloss: 0.134797\n",
      "ROC AUC: 0.8445\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),\n",
    "                          max_depth=int(best['max_depth']),\n",
    "                          min_child_samples=int(best['min_child_samples']),\n",
    "                          subsample=round(best['subsample'],5),\n",
    "                          learning_rate=round(best['learning_rate'],5),\n",
    "                          early_stopping_rounds=100\n",
    "                         )\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_val, y_val)])\n",
    "lgbm_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec17256-fd12-4e73-b184-667dd504c820",
   "metadata": {},
   "source": [
    "### 결과\n",
    "LightGBM ROC AUC: 0.838887  \n",
    "LightGBM 하이퍼파라미터 튜닝 ROC AUC: 0.8424"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680c05a-8a51-46ce-b1ee-461167f50816",
   "metadata": {},
   "source": [
    "- XGBoost ROC AUC: 0.8385\n",
    "- XGBoost 하이퍼파라미터 튜닝 ROC AUC: 0.8424\n",
    "- LightGBM ROC AUC: 0.8388\n",
    "- LightGBM 하이퍼파라미터 튜닝 ROC AUC: 0.8424  \n",
    "=> LightGBM이 가장 성능이 좋았다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
