{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233720ae-3e99-4d67-8c73-c94976f4738d",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dfa0bc8-87a0-47cc-b7aa-5872cf41cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pylot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "cust_df = pd.read_csv('./train.csv', encoding='latin-1')\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c252be40-6f0e-48fb-af93-c2b4ef8dfc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eef98c2-b3b9-4639-9127-b92db02d7c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    73012\n",
      "1     3008\n",
      "Name: count, dtype: int64\n",
      "unsatisfied비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] ==1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print('unsatisfied비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a594822e-eb5c-442e-abd2-4da29bf67dc2",
   "metadata": {},
   "source": [
    "대부분이 만족이며 불만족 비율은 0.04%에 불과하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9cb525-d791-4a81-b155-b2c09a1f9f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2b23e1-5754-432b-9fae-dd62aa541adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처 데이터 shape:(76020, 369)\n"
     ]
    }
   ],
   "source": [
    "cust_df['var3'].replace(-999999,2,inplace=True)\n",
    "cust_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:,-1]\n",
    "print('피처 데이터 shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499b0686-21e6-440b-8981-fd07c49122d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
      "학습 세트 레이블 값 비율\n",
      "TARGET\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: count, dtype: float64\n",
      "테스트 세트 레이블 비율\n",
      "TARGET\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "print('학습 세트 레이블 값 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('테스트 세트 레이블 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae82d5d-b95c-4f68-8d45-4288c01dc9c1",
   "metadata": {},
   "source": [
    "test_size=0.2 이므로 train데이터 : test데이터는 8대2 비율을 유지한다.  \n",
    "학습 데이터와 테스트 데이터의 TARGET값 분포가 원본과 유사하게 나오도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d4dda2-6ce4-44c8-ae4b-c7ceb61ef34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51492d0-60ff-4d94-bf5a-309a64e8880f",
   "metadata": {},
   "source": [
    "## XGBoost 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b1f6c-efd0-49e6-83e5-1e0be7e55371",
   "metadata": {},
   "source": [
    "### XGBoost 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ba47a39-dd6d-474c-a4cd-cf44ee935235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.16022\tvalidation_1-logloss:0.16168\n",
      "[1]\tvalidation_0-logloss:0.15667\tvalidation_1-logloss:0.15864\n",
      "[2]\tvalidation_0-logloss:0.15373\tvalidation_1-logloss:0.15609\n",
      "[3]\tvalidation_0-logloss:0.15124\tvalidation_1-logloss:0.15399\n",
      "[4]\tvalidation_0-logloss:0.14907\tvalidation_1-logloss:0.15215\n",
      "[5]\tvalidation_0-logloss:0.14709\tvalidation_1-logloss:0.15057\n",
      "[6]\tvalidation_0-logloss:0.14537\tvalidation_1-logloss:0.14912\n",
      "[7]\tvalidation_0-logloss:0.14379\tvalidation_1-logloss:0.14789\n",
      "[8]\tvalidation_0-logloss:0.14241\tvalidation_1-logloss:0.14679\n",
      "[9]\tvalidation_0-logloss:0.14111\tvalidation_1-logloss:0.14579\n",
      "[10]\tvalidation_0-logloss:0.13993\tvalidation_1-logloss:0.14488\n",
      "[11]\tvalidation_0-logloss:0.13878\tvalidation_1-logloss:0.14407\n",
      "[12]\tvalidation_0-logloss:0.13773\tvalidation_1-logloss:0.14329\n",
      "[13]\tvalidation_0-logloss:0.13674\tvalidation_1-logloss:0.14257\n",
      "[14]\tvalidation_0-logloss:0.13582\tvalidation_1-logloss:0.14192\n",
      "[15]\tvalidation_0-logloss:0.13497\tvalidation_1-logloss:0.14132\n",
      "[16]\tvalidation_0-logloss:0.13420\tvalidation_1-logloss:0.14077\n",
      "[17]\tvalidation_0-logloss:0.13350\tvalidation_1-logloss:0.14028\n",
      "[18]\tvalidation_0-logloss:0.13288\tvalidation_1-logloss:0.13985\n",
      "[19]\tvalidation_0-logloss:0.13224\tvalidation_1-logloss:0.13940\n",
      "[20]\tvalidation_0-logloss:0.13165\tvalidation_1-logloss:0.13903\n",
      "[21]\tvalidation_0-logloss:0.13105\tvalidation_1-logloss:0.13867\n",
      "[22]\tvalidation_0-logloss:0.13051\tvalidation_1-logloss:0.13836\n",
      "[23]\tvalidation_0-logloss:0.12999\tvalidation_1-logloss:0.13806\n",
      "[24]\tvalidation_0-logloss:0.12953\tvalidation_1-logloss:0.13781\n",
      "[25]\tvalidation_0-logloss:0.12904\tvalidation_1-logloss:0.13759\n",
      "[26]\tvalidation_0-logloss:0.12861\tvalidation_1-logloss:0.13741\n",
      "[27]\tvalidation_0-logloss:0.12820\tvalidation_1-logloss:0.13722\n",
      "[28]\tvalidation_0-logloss:0.12785\tvalidation_1-logloss:0.13702\n",
      "[29]\tvalidation_0-logloss:0.12751\tvalidation_1-logloss:0.13688\n",
      "[30]\tvalidation_0-logloss:0.12717\tvalidation_1-logloss:0.13670\n",
      "[31]\tvalidation_0-logloss:0.12683\tvalidation_1-logloss:0.13652\n",
      "[32]\tvalidation_0-logloss:0.12650\tvalidation_1-logloss:0.13639\n",
      "[33]\tvalidation_0-logloss:0.12619\tvalidation_1-logloss:0.13625\n",
      "[34]\tvalidation_0-logloss:0.12593\tvalidation_1-logloss:0.13614\n",
      "[35]\tvalidation_0-logloss:0.12565\tvalidation_1-logloss:0.13603\n",
      "[36]\tvalidation_0-logloss:0.12536\tvalidation_1-logloss:0.13589\n",
      "[37]\tvalidation_0-logloss:0.12507\tvalidation_1-logloss:0.13583\n",
      "[38]\tvalidation_0-logloss:0.12485\tvalidation_1-logloss:0.13575\n",
      "[39]\tvalidation_0-logloss:0.12459\tvalidation_1-logloss:0.13565\n",
      "[40]\tvalidation_0-logloss:0.12435\tvalidation_1-logloss:0.13558\n",
      "[41]\tvalidation_0-logloss:0.12417\tvalidation_1-logloss:0.13550\n",
      "[42]\tvalidation_0-logloss:0.12396\tvalidation_1-logloss:0.13540\n",
      "[43]\tvalidation_0-logloss:0.12374\tvalidation_1-logloss:0.13534\n",
      "[44]\tvalidation_0-logloss:0.12355\tvalidation_1-logloss:0.13531\n",
      "[45]\tvalidation_0-logloss:0.12336\tvalidation_1-logloss:0.13524\n",
      "[46]\tvalidation_0-logloss:0.12317\tvalidation_1-logloss:0.13522\n",
      "[47]\tvalidation_0-logloss:0.12298\tvalidation_1-logloss:0.13518\n",
      "[48]\tvalidation_0-logloss:0.12278\tvalidation_1-logloss:0.13513\n",
      "[49]\tvalidation_0-logloss:0.12265\tvalidation_1-logloss:0.13513\n",
      "[50]\tvalidation_0-logloss:0.12248\tvalidation_1-logloss:0.13510\n",
      "[51]\tvalidation_0-logloss:0.12234\tvalidation_1-logloss:0.13509\n",
      "[52]\tvalidation_0-logloss:0.12219\tvalidation_1-logloss:0.13505\n",
      "[53]\tvalidation_0-logloss:0.12203\tvalidation_1-logloss:0.13501\n",
      "[54]\tvalidation_0-logloss:0.12189\tvalidation_1-logloss:0.13501\n",
      "[55]\tvalidation_0-logloss:0.12172\tvalidation_1-logloss:0.13498\n",
      "[56]\tvalidation_0-logloss:0.12161\tvalidation_1-logloss:0.13497\n",
      "[57]\tvalidation_0-logloss:0.12147\tvalidation_1-logloss:0.13497\n",
      "[58]\tvalidation_0-logloss:0.12132\tvalidation_1-logloss:0.13496\n",
      "[59]\tvalidation_0-logloss:0.12120\tvalidation_1-logloss:0.13497\n",
      "[60]\tvalidation_0-logloss:0.12103\tvalidation_1-logloss:0.13495\n",
      "[61]\tvalidation_0-logloss:0.12089\tvalidation_1-logloss:0.13495\n",
      "[62]\tvalidation_0-logloss:0.12076\tvalidation_1-logloss:0.13496\n",
      "[63]\tvalidation_0-logloss:0.12065\tvalidation_1-logloss:0.13496\n",
      "[64]\tvalidation_0-logloss:0.12057\tvalidation_1-logloss:0.13496\n",
      "[65]\tvalidation_0-logloss:0.12032\tvalidation_1-logloss:0.13492\n",
      "[66]\tvalidation_0-logloss:0.12026\tvalidation_1-logloss:0.13491\n",
      "[67]\tvalidation_0-logloss:0.12010\tvalidation_1-logloss:0.13489\n",
      "[68]\tvalidation_0-logloss:0.11998\tvalidation_1-logloss:0.13489\n",
      "[69]\tvalidation_0-logloss:0.11980\tvalidation_1-logloss:0.13486\n",
      "[70]\tvalidation_0-logloss:0.11961\tvalidation_1-logloss:0.13484\n",
      "[71]\tvalidation_0-logloss:0.11954\tvalidation_1-logloss:0.13485\n",
      "[72]\tvalidation_0-logloss:0.11944\tvalidation_1-logloss:0.13485\n",
      "[73]\tvalidation_0-logloss:0.11929\tvalidation_1-logloss:0.13485\n",
      "[74]\tvalidation_0-logloss:0.11909\tvalidation_1-logloss:0.13484\n",
      "[75]\tvalidation_0-logloss:0.11902\tvalidation_1-logloss:0.13484\n",
      "[76]\tvalidation_0-logloss:0.11883\tvalidation_1-logloss:0.13484\n",
      "[77]\tvalidation_0-logloss:0.11870\tvalidation_1-logloss:0.13485\n",
      "[78]\tvalidation_0-logloss:0.11866\tvalidation_1-logloss:0.13483\n",
      "[79]\tvalidation_0-logloss:0.11861\tvalidation_1-logloss:0.13481\n",
      "[80]\tvalidation_0-logloss:0.11856\tvalidation_1-logloss:0.13481\n",
      "[81]\tvalidation_0-logloss:0.11850\tvalidation_1-logloss:0.13481\n",
      "[82]\tvalidation_0-logloss:0.11846\tvalidation_1-logloss:0.13479\n",
      "[83]\tvalidation_0-logloss:0.11841\tvalidation_1-logloss:0.13479\n",
      "[84]\tvalidation_0-logloss:0.11828\tvalidation_1-logloss:0.13478\n",
      "[85]\tvalidation_0-logloss:0.11819\tvalidation_1-logloss:0.13477\n",
      "[86]\tvalidation_0-logloss:0.11816\tvalidation_1-logloss:0.13476\n",
      "[87]\tvalidation_0-logloss:0.11810\tvalidation_1-logloss:0.13476\n",
      "[88]\tvalidation_0-logloss:0.11805\tvalidation_1-logloss:0.13476\n",
      "[89]\tvalidation_0-logloss:0.11803\tvalidation_1-logloss:0.13475\n",
      "[90]\tvalidation_0-logloss:0.11800\tvalidation_1-logloss:0.13474\n",
      "[91]\tvalidation_0-logloss:0.11789\tvalidation_1-logloss:0.13473\n",
      "[92]\tvalidation_0-logloss:0.11786\tvalidation_1-logloss:0.13473\n",
      "[93]\tvalidation_0-logloss:0.11774\tvalidation_1-logloss:0.13472\n",
      "[94]\tvalidation_0-logloss:0.11761\tvalidation_1-logloss:0.13471\n",
      "[95]\tvalidation_0-logloss:0.11759\tvalidation_1-logloss:0.13470\n",
      "[96]\tvalidation_0-logloss:0.11747\tvalidation_1-logloss:0.13469\n",
      "[97]\tvalidation_0-logloss:0.11743\tvalidation_1-logloss:0.13470\n",
      "[98]\tvalidation_0-logloss:0.11740\tvalidation_1-logloss:0.13469\n",
      "[99]\tvalidation_0-logloss:0.11736\tvalidation_1-logloss:0.13468\n",
      "[100]\tvalidation_0-logloss:0.11728\tvalidation_1-logloss:0.13470\n",
      "[101]\tvalidation_0-logloss:0.11727\tvalidation_1-logloss:0.13468\n",
      "[102]\tvalidation_0-logloss:0.11714\tvalidation_1-logloss:0.13467\n",
      "[103]\tvalidation_0-logloss:0.11708\tvalidation_1-logloss:0.13466\n",
      "[104]\tvalidation_0-logloss:0.11707\tvalidation_1-logloss:0.13465\n",
      "[105]\tvalidation_0-logloss:0.11693\tvalidation_1-logloss:0.13466\n",
      "[106]\tvalidation_0-logloss:0.11688\tvalidation_1-logloss:0.13467\n",
      "[107]\tvalidation_0-logloss:0.11686\tvalidation_1-logloss:0.13467\n",
      "[108]\tvalidation_0-logloss:0.11675\tvalidation_1-logloss:0.13466\n",
      "[109]\tvalidation_0-logloss:0.11671\tvalidation_1-logloss:0.13466\n",
      "[110]\tvalidation_0-logloss:0.11668\tvalidation_1-logloss:0.13466\n",
      "[111]\tvalidation_0-logloss:0.11666\tvalidation_1-logloss:0.13466\n",
      "[112]\tvalidation_0-logloss:0.11656\tvalidation_1-logloss:0.13466\n",
      "[113]\tvalidation_0-logloss:0.11651\tvalidation_1-logloss:0.13466\n",
      "[114]\tvalidation_0-logloss:0.11644\tvalidation_1-logloss:0.13467\n",
      "[115]\tvalidation_0-logloss:0.11643\tvalidation_1-logloss:0.13467\n",
      "[116]\tvalidation_0-logloss:0.11640\tvalidation_1-logloss:0.13468\n",
      "[117]\tvalidation_0-logloss:0.11637\tvalidation_1-logloss:0.13469\n",
      "[118]\tvalidation_0-logloss:0.11631\tvalidation_1-logloss:0.13471\n",
      "[119]\tvalidation_0-logloss:0.11629\tvalidation_1-logloss:0.13470\n",
      "[120]\tvalidation_0-logloss:0.11628\tvalidation_1-logloss:0.13471\n",
      "[121]\tvalidation_0-logloss:0.11627\tvalidation_1-logloss:0.13471\n",
      "[122]\tvalidation_0-logloss:0.11623\tvalidation_1-logloss:0.13471\n",
      "[123]\tvalidation_0-logloss:0.11620\tvalidation_1-logloss:0.13471\n",
      "[124]\tvalidation_0-logloss:0.11619\tvalidation_1-logloss:0.13471\n",
      "[125]\tvalidation_0-logloss:0.11605\tvalidation_1-logloss:0.13475\n",
      "[126]\tvalidation_0-logloss:0.11599\tvalidation_1-logloss:0.13475\n",
      "[127]\tvalidation_0-logloss:0.11595\tvalidation_1-logloss:0.13476\n",
      "[128]\tvalidation_0-logloss:0.11590\tvalidation_1-logloss:0.13477\n",
      "[129]\tvalidation_0-logloss:0.11586\tvalidation_1-logloss:0.13477\n",
      "[130]\tvalidation_0-logloss:0.11577\tvalidation_1-logloss:0.13476\n",
      "[131]\tvalidation_0-logloss:0.11565\tvalidation_1-logloss:0.13479\n",
      "[132]\tvalidation_0-logloss:0.11550\tvalidation_1-logloss:0.13477\n",
      "[133]\tvalidation_0-logloss:0.11547\tvalidation_1-logloss:0.13477\n",
      "[134]\tvalidation_0-logloss:0.11545\tvalidation_1-logloss:0.13477\n",
      "[135]\tvalidation_0-logloss:0.11541\tvalidation_1-logloss:0.13477\n",
      "[136]\tvalidation_0-logloss:0.11530\tvalidation_1-logloss:0.13476\n",
      "[137]\tvalidation_0-logloss:0.11522\tvalidation_1-logloss:0.13477\n",
      "[138]\tvalidation_0-logloss:0.11518\tvalidation_1-logloss:0.13474\n",
      "[139]\tvalidation_0-logloss:0.11509\tvalidation_1-logloss:0.13475\n",
      "[140]\tvalidation_0-logloss:0.11500\tvalidation_1-logloss:0.13479\n",
      "[141]\tvalidation_0-logloss:0.11498\tvalidation_1-logloss:0.13479\n",
      "[142]\tvalidation_0-logloss:0.11496\tvalidation_1-logloss:0.13479\n",
      "[143]\tvalidation_0-logloss:0.11489\tvalidation_1-logloss:0.13479\n",
      "[144]\tvalidation_0-logloss:0.11484\tvalidation_1-logloss:0.13479\n",
      "[145]\tvalidation_0-logloss:0.11483\tvalidation_1-logloss:0.13479\n",
      "[146]\tvalidation_0-logloss:0.11477\tvalidation_1-logloss:0.13481\n",
      "[147]\tvalidation_0-logloss:0.11476\tvalidation_1-logloss:0.13481\n",
      "[148]\tvalidation_0-logloss:0.11473\tvalidation_1-logloss:0.13481\n",
      "[149]\tvalidation_0-logloss:0.11469\tvalidation_1-logloss:0.13482\n",
      "[150]\tvalidation_0-logloss:0.11459\tvalidation_1-logloss:0.13483\n",
      "[151]\tvalidation_0-logloss:0.11440\tvalidation_1-logloss:0.13483\n",
      "[152]\tvalidation_0-logloss:0.11436\tvalidation_1-logloss:0.13483\n",
      "[153]\tvalidation_0-logloss:0.11435\tvalidation_1-logloss:0.13483\n",
      "[154]\tvalidation_0-logloss:0.11429\tvalidation_1-logloss:0.13482\n",
      "[155]\tvalidation_0-logloss:0.11419\tvalidation_1-logloss:0.13482\n",
      "[156]\tvalidation_0-logloss:0.11417\tvalidation_1-logloss:0.13483\n",
      "[157]\tvalidation_0-logloss:0.11414\tvalidation_1-logloss:0.13485\n",
      "[158]\tvalidation_0-logloss:0.11405\tvalidation_1-logloss:0.13487\n",
      "[159]\tvalidation_0-logloss:0.11403\tvalidation_1-logloss:0.13487\n",
      "[160]\tvalidation_0-logloss:0.11402\tvalidation_1-logloss:0.13488\n",
      "[161]\tvalidation_0-logloss:0.11398\tvalidation_1-logloss:0.13488\n",
      "[162]\tvalidation_0-logloss:0.11395\tvalidation_1-logloss:0.13489\n",
      "[163]\tvalidation_0-logloss:0.11392\tvalidation_1-logloss:0.13488\n",
      "[164]\tvalidation_0-logloss:0.11389\tvalidation_1-logloss:0.13489\n",
      "[165]\tvalidation_0-logloss:0.11388\tvalidation_1-logloss:0.13489\n",
      "[166]\tvalidation_0-logloss:0.11376\tvalidation_1-logloss:0.13490\n",
      "[167]\tvalidation_0-logloss:0.11375\tvalidation_1-logloss:0.13489\n",
      "[168]\tvalidation_0-logloss:0.11372\tvalidation_1-logloss:0.13491\n",
      "[169]\tvalidation_0-logloss:0.11371\tvalidation_1-logloss:0.13490\n",
      "[170]\tvalidation_0-logloss:0.11367\tvalidation_1-logloss:0.13490\n",
      "[171]\tvalidation_0-logloss:0.11363\tvalidation_1-logloss:0.13490\n",
      "[172]\tvalidation_0-logloss:0.11359\tvalidation_1-logloss:0.13492\n",
      "[173]\tvalidation_0-logloss:0.11352\tvalidation_1-logloss:0.13490\n",
      "[174]\tvalidation_0-logloss:0.11349\tvalidation_1-logloss:0.13490\n",
      "[175]\tvalidation_0-logloss:0.11348\tvalidation_1-logloss:0.13490\n",
      "[176]\tvalidation_0-logloss:0.11344\tvalidation_1-logloss:0.13492\n",
      "[177]\tvalidation_0-logloss:0.11342\tvalidation_1-logloss:0.13493\n",
      "[178]\tvalidation_0-logloss:0.11338\tvalidation_1-logloss:0.13494\n",
      "[179]\tvalidation_0-logloss:0.11337\tvalidation_1-logloss:0.13494\n",
      "[180]\tvalidation_0-logloss:0.11334\tvalidation_1-logloss:0.13495\n",
      "[181]\tvalidation_0-logloss:0.11324\tvalidation_1-logloss:0.13494\n",
      "[182]\tvalidation_0-logloss:0.11317\tvalidation_1-logloss:0.13497\n",
      "[183]\tvalidation_0-logloss:0.11314\tvalidation_1-logloss:0.13497\n",
      "[184]\tvalidation_0-logloss:0.11312\tvalidation_1-logloss:0.13496\n",
      "[185]\tvalidation_0-logloss:0.11310\tvalidation_1-logloss:0.13496\n",
      "[186]\tvalidation_0-logloss:0.11308\tvalidation_1-logloss:0.13497\n",
      "[187]\tvalidation_0-logloss:0.11306\tvalidation_1-logloss:0.13496\n",
      "[188]\tvalidation_0-logloss:0.11300\tvalidation_1-logloss:0.13496\n",
      "[189]\tvalidation_0-logloss:0.11296\tvalidation_1-logloss:0.13497\n",
      "[190]\tvalidation_0-logloss:0.11294\tvalidation_1-logloss:0.13498\n",
      "[191]\tvalidation_0-logloss:0.11290\tvalidation_1-logloss:0.13498\n",
      "[192]\tvalidation_0-logloss:0.11288\tvalidation_1-logloss:0.13498\n",
      "[193]\tvalidation_0-logloss:0.11286\tvalidation_1-logloss:0.13498\n",
      "[194]\tvalidation_0-logloss:0.11284\tvalidation_1-logloss:0.13498\n",
      "[195]\tvalidation_0-logloss:0.11282\tvalidation_1-logloss:0.13499\n",
      "[196]\tvalidation_0-logloss:0.11280\tvalidation_1-logloss:0.13498\n",
      "[197]\tvalidation_0-logloss:0.11273\tvalidation_1-logloss:0.13502\n",
      "[198]\tvalidation_0-logloss:0.11267\tvalidation_1-logloss:0.13501\n",
      "[199]\tvalidation_0-logloss:0.11258\tvalidation_1-logloss:0.13504\n",
      "[200]\tvalidation_0-logloss:0.11248\tvalidation_1-logloss:0.13503\n",
      "[201]\tvalidation_0-logloss:0.11239\tvalidation_1-logloss:0.13507\n",
      "[202]\tvalidation_0-logloss:0.11236\tvalidation_1-logloss:0.13508\n",
      "[203]\tvalidation_0-logloss:0.11234\tvalidation_1-logloss:0.13509\n",
      "[204]\tvalidation_0-logloss:0.11219\tvalidation_1-logloss:0.13511\n",
      "[205]\tvalidation_0-logloss:0.11217\tvalidation_1-logloss:0.13511\n",
      "[206]\tvalidation_0-logloss:0.11213\tvalidation_1-logloss:0.13510\n",
      "[207]\tvalidation_0-logloss:0.11211\tvalidation_1-logloss:0.13511\n",
      "[208]\tvalidation_0-logloss:0.11209\tvalidation_1-logloss:0.13511\n",
      "[209]\tvalidation_0-logloss:0.11207\tvalidation_1-logloss:0.13513\n",
      "[210]\tvalidation_0-logloss:0.11203\tvalidation_1-logloss:0.13513\n",
      "[211]\tvalidation_0-logloss:0.11202\tvalidation_1-logloss:0.13513\n",
      "[212]\tvalidation_0-logloss:0.11192\tvalidation_1-logloss:0.13511\n",
      "[213]\tvalidation_0-logloss:0.11190\tvalidation_1-logloss:0.13511\n",
      "[214]\tvalidation_0-logloss:0.11181\tvalidation_1-logloss:0.13513\n",
      "[215]\tvalidation_0-logloss:0.11180\tvalidation_1-logloss:0.13513\n",
      "[216]\tvalidation_0-logloss:0.11179\tvalidation_1-logloss:0.13513\n",
      "[217]\tvalidation_0-logloss:0.11171\tvalidation_1-logloss:0.13514\n",
      "[218]\tvalidation_0-logloss:0.11163\tvalidation_1-logloss:0.13515\n",
      "[219]\tvalidation_0-logloss:0.11152\tvalidation_1-logloss:0.13515\n",
      "[220]\tvalidation_0-logloss:0.11145\tvalidation_1-logloss:0.13519\n",
      "[221]\tvalidation_0-logloss:0.11138\tvalidation_1-logloss:0.13520\n",
      "[222]\tvalidation_0-logloss:0.11136\tvalidation_1-logloss:0.13520\n",
      "[223]\tvalidation_0-logloss:0.11130\tvalidation_1-logloss:0.13521\n",
      "[224]\tvalidation_0-logloss:0.11129\tvalidation_1-logloss:0.13521\n",
      "[225]\tvalidation_0-logloss:0.11127\tvalidation_1-logloss:0.13522\n",
      "[226]\tvalidation_0-logloss:0.11125\tvalidation_1-logloss:0.13523\n",
      "[227]\tvalidation_0-logloss:0.11123\tvalidation_1-logloss:0.13523\n",
      "[228]\tvalidation_0-logloss:0.11117\tvalidation_1-logloss:0.13525\n",
      "[229]\tvalidation_0-logloss:0.11113\tvalidation_1-logloss:0.13525\n",
      "[230]\tvalidation_0-logloss:0.11111\tvalidation_1-logloss:0.13525\n",
      "[231]\tvalidation_0-logloss:0.11110\tvalidation_1-logloss:0.13525\n",
      "[232]\tvalidation_0-logloss:0.11097\tvalidation_1-logloss:0.13528\n",
      "[233]\tvalidation_0-logloss:0.11090\tvalidation_1-logloss:0.13528\n",
      "[234]\tvalidation_0-logloss:0.11085\tvalidation_1-logloss:0.13528\n",
      "[235]\tvalidation_0-logloss:0.11084\tvalidation_1-logloss:0.13528\n",
      "[236]\tvalidation_0-logloss:0.11081\tvalidation_1-logloss:0.13529\n",
      "[237]\tvalidation_0-logloss:0.11080\tvalidation_1-logloss:0.13529\n",
      "[238]\tvalidation_0-logloss:0.11074\tvalidation_1-logloss:0.13530\n",
      "[239]\tvalidation_0-logloss:0.11069\tvalidation_1-logloss:0.13532\n",
      "[240]\tvalidation_0-logloss:0.11056\tvalidation_1-logloss:0.13532\n",
      "[241]\tvalidation_0-logloss:0.11054\tvalidation_1-logloss:0.13531\n",
      "[242]\tvalidation_0-logloss:0.11052\tvalidation_1-logloss:0.13531\n",
      "[243]\tvalidation_0-logloss:0.11049\tvalidation_1-logloss:0.13532\n",
      "[244]\tvalidation_0-logloss:0.11048\tvalidation_1-logloss:0.13533\n",
      "[245]\tvalidation_0-logloss:0.11040\tvalidation_1-logloss:0.13535\n",
      "[246]\tvalidation_0-logloss:0.11037\tvalidation_1-logloss:0.13536\n",
      "[247]\tvalidation_0-logloss:0.11030\tvalidation_1-logloss:0.13533\n",
      "[248]\tvalidation_0-logloss:0.11023\tvalidation_1-logloss:0.13532\n",
      "[249]\tvalidation_0-logloss:0.11021\tvalidation_1-logloss:0.13532\n",
      "[250]\tvalidation_0-logloss:0.11016\tvalidation_1-logloss:0.13532\n",
      "[251]\tvalidation_0-logloss:0.11009\tvalidation_1-logloss:0.13534\n",
      "[252]\tvalidation_0-logloss:0.10997\tvalidation_1-logloss:0.13537\n",
      "[253]\tvalidation_0-logloss:0.10996\tvalidation_1-logloss:0.13537\n",
      "[254]\tvalidation_0-logloss:0.10986\tvalidation_1-logloss:0.13539\n",
      "[255]\tvalidation_0-logloss:0.10985\tvalidation_1-logloss:0.13539\n",
      "[256]\tvalidation_0-logloss:0.10983\tvalidation_1-logloss:0.13539\n",
      "[257]\tvalidation_0-logloss:0.10977\tvalidation_1-logloss:0.13539\n",
      "[258]\tvalidation_0-logloss:0.10967\tvalidation_1-logloss:0.13542\n",
      "[259]\tvalidation_0-logloss:0.10954\tvalidation_1-logloss:0.13542\n",
      "[260]\tvalidation_0-logloss:0.10952\tvalidation_1-logloss:0.13543\n",
      "[261]\tvalidation_0-logloss:0.10950\tvalidation_1-logloss:0.13544\n",
      "[262]\tvalidation_0-logloss:0.10949\tvalidation_1-logloss:0.13544\n",
      "[263]\tvalidation_0-logloss:0.10948\tvalidation_1-logloss:0.13544\n",
      "[264]\tvalidation_0-logloss:0.10940\tvalidation_1-logloss:0.13548\n",
      "[265]\tvalidation_0-logloss:0.10939\tvalidation_1-logloss:0.13548\n",
      "[266]\tvalidation_0-logloss:0.10937\tvalidation_1-logloss:0.13548\n",
      "[267]\tvalidation_0-logloss:0.10931\tvalidation_1-logloss:0.13548\n",
      "[268]\tvalidation_0-logloss:0.10930\tvalidation_1-logloss:0.13547\n",
      "[269]\tvalidation_0-logloss:0.10929\tvalidation_1-logloss:0.13547\n",
      "[270]\tvalidation_0-logloss:0.10923\tvalidation_1-logloss:0.13549\n",
      "[271]\tvalidation_0-logloss:0.10921\tvalidation_1-logloss:0.13549\n",
      "[272]\tvalidation_0-logloss:0.10920\tvalidation_1-logloss:0.13549\n",
      "[273]\tvalidation_0-logloss:0.10908\tvalidation_1-logloss:0.13550\n",
      "[274]\tvalidation_0-logloss:0.10902\tvalidation_1-logloss:0.13554\n",
      "[275]\tvalidation_0-logloss:0.10896\tvalidation_1-logloss:0.13554\n",
      "[276]\tvalidation_0-logloss:0.10886\tvalidation_1-logloss:0.13557\n",
      "[277]\tvalidation_0-logloss:0.10879\tvalidation_1-logloss:0.13557\n",
      "[278]\tvalidation_0-logloss:0.10873\tvalidation_1-logloss:0.13552\n",
      "[279]\tvalidation_0-logloss:0.10872\tvalidation_1-logloss:0.13552\n",
      "[280]\tvalidation_0-logloss:0.10866\tvalidation_1-logloss:0.13555\n",
      "[281]\tvalidation_0-logloss:0.10865\tvalidation_1-logloss:0.13555\n",
      "[282]\tvalidation_0-logloss:0.10860\tvalidation_1-logloss:0.13557\n",
      "[283]\tvalidation_0-logloss:0.10857\tvalidation_1-logloss:0.13558\n",
      "[284]\tvalidation_0-logloss:0.10842\tvalidation_1-logloss:0.13559\n",
      "[285]\tvalidation_0-logloss:0.10836\tvalidation_1-logloss:0.13559\n",
      "[286]\tvalidation_0-logloss:0.10834\tvalidation_1-logloss:0.13558\n",
      "[287]\tvalidation_0-logloss:0.10832\tvalidation_1-logloss:0.13557\n",
      "[288]\tvalidation_0-logloss:0.10830\tvalidation_1-logloss:0.13558\n",
      "[289]\tvalidation_0-logloss:0.10818\tvalidation_1-logloss:0.13558\n",
      "[290]\tvalidation_0-logloss:0.10815\tvalidation_1-logloss:0.13558\n",
      "[291]\tvalidation_0-logloss:0.10802\tvalidation_1-logloss:0.13559\n",
      "[292]\tvalidation_0-logloss:0.10793\tvalidation_1-logloss:0.13561\n",
      "[293]\tvalidation_0-logloss:0.10788\tvalidation_1-logloss:0.13557\n",
      "[294]\tvalidation_0-logloss:0.10785\tvalidation_1-logloss:0.13558\n",
      "[295]\tvalidation_0-logloss:0.10785\tvalidation_1-logloss:0.13558\n",
      "[296]\tvalidation_0-logloss:0.10780\tvalidation_1-logloss:0.13558\n",
      "[297]\tvalidation_0-logloss:0.10777\tvalidation_1-logloss:0.13559\n",
      "[298]\tvalidation_0-logloss:0.10776\tvalidation_1-logloss:0.13560\n",
      "[299]\tvalidation_0-logloss:0.10769\tvalidation_1-logloss:0.13562\n",
      "[300]\tvalidation_0-logloss:0.10767\tvalidation_1-logloss:0.13563\n",
      "[301]\tvalidation_0-logloss:0.10759\tvalidation_1-logloss:0.13565\n",
      "[302]\tvalidation_0-logloss:0.10748\tvalidation_1-logloss:0.13566\n",
      "[303]\tvalidation_0-logloss:0.10742\tvalidation_1-logloss:0.13567\n",
      "[304]\tvalidation_0-logloss:0.10734\tvalidation_1-logloss:0.13569\n",
      "[305]\tvalidation_0-logloss:0.10718\tvalidation_1-logloss:0.13573\n",
      "[306]\tvalidation_0-logloss:0.10705\tvalidation_1-logloss:0.13574\n",
      "[307]\tvalidation_0-logloss:0.10694\tvalidation_1-logloss:0.13574\n",
      "[308]\tvalidation_0-logloss:0.10685\tvalidation_1-logloss:0.13575\n",
      "[309]\tvalidation_0-logloss:0.10676\tvalidation_1-logloss:0.13576\n",
      "[310]\tvalidation_0-logloss:0.10670\tvalidation_1-logloss:0.13578\n",
      "[311]\tvalidation_0-logloss:0.10664\tvalidation_1-logloss:0.13580\n",
      "[312]\tvalidation_0-logloss:0.10653\tvalidation_1-logloss:0.13582\n",
      "[313]\tvalidation_0-logloss:0.10645\tvalidation_1-logloss:0.13582\n",
      "[314]\tvalidation_0-logloss:0.10635\tvalidation_1-logloss:0.13585\n",
      "[315]\tvalidation_0-logloss:0.10634\tvalidation_1-logloss:0.13585\n",
      "[316]\tvalidation_0-logloss:0.10632\tvalidation_1-logloss:0.13586\n",
      "[317]\tvalidation_0-logloss:0.10625\tvalidation_1-logloss:0.13587\n",
      "[318]\tvalidation_0-logloss:0.10619\tvalidation_1-logloss:0.13588\n",
      "[319]\tvalidation_0-logloss:0.10612\tvalidation_1-logloss:0.13591\n",
      "[320]\tvalidation_0-logloss:0.10605\tvalidation_1-logloss:0.13590\n",
      "[321]\tvalidation_0-logloss:0.10591\tvalidation_1-logloss:0.13590\n",
      "[322]\tvalidation_0-logloss:0.10582\tvalidation_1-logloss:0.13591\n",
      "[323]\tvalidation_0-logloss:0.10581\tvalidation_1-logloss:0.13591\n",
      "[324]\tvalidation_0-logloss:0.10574\tvalidation_1-logloss:0.13591\n",
      "[325]\tvalidation_0-logloss:0.10572\tvalidation_1-logloss:0.13591\n",
      "[326]\tvalidation_0-logloss:0.10571\tvalidation_1-logloss:0.13591\n",
      "[327]\tvalidation_0-logloss:0.10566\tvalidation_1-logloss:0.13592\n",
      "[328]\tvalidation_0-logloss:0.10556\tvalidation_1-logloss:0.13595\n",
      "[329]\tvalidation_0-logloss:0.10555\tvalidation_1-logloss:0.13595\n",
      "[330]\tvalidation_0-logloss:0.10553\tvalidation_1-logloss:0.13595\n",
      "[331]\tvalidation_0-logloss:0.10550\tvalidation_1-logloss:0.13595\n",
      "[332]\tvalidation_0-logloss:0.10548\tvalidation_1-logloss:0.13595\n",
      "[333]\tvalidation_0-logloss:0.10537\tvalidation_1-logloss:0.13596\n",
      "[334]\tvalidation_0-logloss:0.10524\tvalidation_1-logloss:0.13599\n",
      "[335]\tvalidation_0-logloss:0.10514\tvalidation_1-logloss:0.13598\n",
      "[336]\tvalidation_0-logloss:0.10503\tvalidation_1-logloss:0.13597\n",
      "[337]\tvalidation_0-logloss:0.10490\tvalidation_1-logloss:0.13599\n",
      "[338]\tvalidation_0-logloss:0.10482\tvalidation_1-logloss:0.13600\n",
      "[339]\tvalidation_0-logloss:0.10481\tvalidation_1-logloss:0.13600\n",
      "[340]\tvalidation_0-logloss:0.10479\tvalidation_1-logloss:0.13601\n",
      "[341]\tvalidation_0-logloss:0.10471\tvalidation_1-logloss:0.13603\n",
      "[342]\tvalidation_0-logloss:0.10468\tvalidation_1-logloss:0.13604\n",
      "[343]\tvalidation_0-logloss:0.10466\tvalidation_1-logloss:0.13606\n",
      "[344]\tvalidation_0-logloss:0.10461\tvalidation_1-logloss:0.13605\n",
      "[345]\tvalidation_0-logloss:0.10460\tvalidation_1-logloss:0.13605\n",
      "[346]\tvalidation_0-logloss:0.10455\tvalidation_1-logloss:0.13602\n",
      "[347]\tvalidation_0-logloss:0.10441\tvalidation_1-logloss:0.13601\n",
      "[348]\tvalidation_0-logloss:0.10439\tvalidation_1-logloss:0.13601\n",
      "[349]\tvalidation_0-logloss:0.10436\tvalidation_1-logloss:0.13600\n",
      "[350]\tvalidation_0-logloss:0.10431\tvalidation_1-logloss:0.13602\n",
      "[351]\tvalidation_0-logloss:0.10429\tvalidation_1-logloss:0.13602\n",
      "[352]\tvalidation_0-logloss:0.10418\tvalidation_1-logloss:0.13604\n",
      "[353]\tvalidation_0-logloss:0.10411\tvalidation_1-logloss:0.13604\n",
      "[354]\tvalidation_0-logloss:0.10406\tvalidation_1-logloss:0.13606\n",
      "[355]\tvalidation_0-logloss:0.10401\tvalidation_1-logloss:0.13608\n",
      "[356]\tvalidation_0-logloss:0.10399\tvalidation_1-logloss:0.13608\n",
      "[357]\tvalidation_0-logloss:0.10390\tvalidation_1-logloss:0.13608\n",
      "[358]\tvalidation_0-logloss:0.10388\tvalidation_1-logloss:0.13608\n",
      "[359]\tvalidation_0-logloss:0.10387\tvalidation_1-logloss:0.13610\n",
      "[360]\tvalidation_0-logloss:0.10385\tvalidation_1-logloss:0.13610\n",
      "[361]\tvalidation_0-logloss:0.10370\tvalidation_1-logloss:0.13612\n",
      "[362]\tvalidation_0-logloss:0.10368\tvalidation_1-logloss:0.13613\n",
      "[363]\tvalidation_0-logloss:0.10366\tvalidation_1-logloss:0.13613\n",
      "[364]\tvalidation_0-logloss:0.10361\tvalidation_1-logloss:0.13611\n",
      "[365]\tvalidation_0-logloss:0.10357\tvalidation_1-logloss:0.13611\n",
      "[366]\tvalidation_0-logloss:0.10353\tvalidation_1-logloss:0.13613\n",
      "[367]\tvalidation_0-logloss:0.10349\tvalidation_1-logloss:0.13615\n",
      "[368]\tvalidation_0-logloss:0.10348\tvalidation_1-logloss:0.13616\n",
      "[369]\tvalidation_0-logloss:0.10346\tvalidation_1-logloss:0.13616\n",
      "[370]\tvalidation_0-logloss:0.10341\tvalidation_1-logloss:0.13617\n",
      "[371]\tvalidation_0-logloss:0.10336\tvalidation_1-logloss:0.13617\n",
      "[372]\tvalidation_0-logloss:0.10326\tvalidation_1-logloss:0.13618\n",
      "[373]\tvalidation_0-logloss:0.10325\tvalidation_1-logloss:0.13619\n",
      "[374]\tvalidation_0-logloss:0.10321\tvalidation_1-logloss:0.13620\n",
      "[375]\tvalidation_0-logloss:0.10317\tvalidation_1-logloss:0.13622\n",
      "[376]\tvalidation_0-logloss:0.10312\tvalidation_1-logloss:0.13623\n",
      "[377]\tvalidation_0-logloss:0.10300\tvalidation_1-logloss:0.13627\n",
      "[378]\tvalidation_0-logloss:0.10290\tvalidation_1-logloss:0.13629\n",
      "[379]\tvalidation_0-logloss:0.10288\tvalidation_1-logloss:0.13630\n",
      "[380]\tvalidation_0-logloss:0.10286\tvalidation_1-logloss:0.13629\n",
      "[381]\tvalidation_0-logloss:0.10284\tvalidation_1-logloss:0.13630\n",
      "[382]\tvalidation_0-logloss:0.10275\tvalidation_1-logloss:0.13633\n",
      "[383]\tvalidation_0-logloss:0.10273\tvalidation_1-logloss:0.13635\n",
      "[384]\tvalidation_0-logloss:0.10271\tvalidation_1-logloss:0.13636\n",
      "[385]\tvalidation_0-logloss:0.10269\tvalidation_1-logloss:0.13636\n",
      "[386]\tvalidation_0-logloss:0.10261\tvalidation_1-logloss:0.13638\n",
      "[387]\tvalidation_0-logloss:0.10257\tvalidation_1-logloss:0.13638\n",
      "[388]\tvalidation_0-logloss:0.10255\tvalidation_1-logloss:0.13638\n",
      "[389]\tvalidation_0-logloss:0.10254\tvalidation_1-logloss:0.13639\n",
      "[390]\tvalidation_0-logloss:0.10251\tvalidation_1-logloss:0.13641\n",
      "[391]\tvalidation_0-logloss:0.10249\tvalidation_1-logloss:0.13642\n",
      "[392]\tvalidation_0-logloss:0.10235\tvalidation_1-logloss:0.13640\n",
      "[393]\tvalidation_0-logloss:0.10231\tvalidation_1-logloss:0.13643\n",
      "[394]\tvalidation_0-logloss:0.10225\tvalidation_1-logloss:0.13643\n",
      "[395]\tvalidation_0-logloss:0.10218\tvalidation_1-logloss:0.13645\n",
      "[396]\tvalidation_0-logloss:0.10216\tvalidation_1-logloss:0.13645\n",
      "[397]\tvalidation_0-logloss:0.10209\tvalidation_1-logloss:0.13648\n",
      "[398]\tvalidation_0-logloss:0.10204\tvalidation_1-logloss:0.13649\n",
      "[399]\tvalidation_0-logloss:0.10201\tvalidation_1-logloss:0.13652\n",
      "[400]\tvalidation_0-logloss:0.10195\tvalidation_1-logloss:0.13652\n",
      "[401]\tvalidation_0-logloss:0.10193\tvalidation_1-logloss:0.13653\n",
      "[402]\tvalidation_0-logloss:0.10191\tvalidation_1-logloss:0.13653\n",
      "[403]\tvalidation_0-logloss:0.10189\tvalidation_1-logloss:0.13655\n",
      "[404]\tvalidation_0-logloss:0.10177\tvalidation_1-logloss:0.13655\n",
      "[405]\tvalidation_0-logloss:0.10174\tvalidation_1-logloss:0.13654\n",
      "[406]\tvalidation_0-logloss:0.10165\tvalidation_1-logloss:0.13656\n",
      "[407]\tvalidation_0-logloss:0.10162\tvalidation_1-logloss:0.13657\n",
      "[408]\tvalidation_0-logloss:0.10159\tvalidation_1-logloss:0.13658\n",
      "[409]\tvalidation_0-logloss:0.10153\tvalidation_1-logloss:0.13660\n",
      "[410]\tvalidation_0-logloss:0.10149\tvalidation_1-logloss:0.13661\n",
      "[411]\tvalidation_0-logloss:0.10148\tvalidation_1-logloss:0.13661\n",
      "[412]\tvalidation_0-logloss:0.10147\tvalidation_1-logloss:0.13662\n",
      "[413]\tvalidation_0-logloss:0.10146\tvalidation_1-logloss:0.13663\n",
      "[414]\tvalidation_0-logloss:0.10145\tvalidation_1-logloss:0.13662\n",
      "[415]\tvalidation_0-logloss:0.10143\tvalidation_1-logloss:0.13662\n",
      "[416]\tvalidation_0-logloss:0.10142\tvalidation_1-logloss:0.13663\n",
      "[417]\tvalidation_0-logloss:0.10139\tvalidation_1-logloss:0.13664\n",
      "[418]\tvalidation_0-logloss:0.10135\tvalidation_1-logloss:0.13666\n",
      "[419]\tvalidation_0-logloss:0.10133\tvalidation_1-logloss:0.13667\n",
      "[420]\tvalidation_0-logloss:0.10129\tvalidation_1-logloss:0.13668\n",
      "[421]\tvalidation_0-logloss:0.10125\tvalidation_1-logloss:0.13671\n",
      "[422]\tvalidation_0-logloss:0.10118\tvalidation_1-logloss:0.13671\n",
      "[423]\tvalidation_0-logloss:0.10110\tvalidation_1-logloss:0.13674\n",
      "[424]\tvalidation_0-logloss:0.10106\tvalidation_1-logloss:0.13675\n",
      "[425]\tvalidation_0-logloss:0.10105\tvalidation_1-logloss:0.13676\n",
      "[426]\tvalidation_0-logloss:0.10104\tvalidation_1-logloss:0.13676\n",
      "[427]\tvalidation_0-logloss:0.10102\tvalidation_1-logloss:0.13678\n",
      "[428]\tvalidation_0-logloss:0.10101\tvalidation_1-logloss:0.13678\n",
      "[429]\tvalidation_0-logloss:0.10100\tvalidation_1-logloss:0.13678\n",
      "[430]\tvalidation_0-logloss:0.10094\tvalidation_1-logloss:0.13680\n",
      "[431]\tvalidation_0-logloss:0.10093\tvalidation_1-logloss:0.13681\n",
      "[432]\tvalidation_0-logloss:0.10083\tvalidation_1-logloss:0.13683\n",
      "[433]\tvalidation_0-logloss:0.10071\tvalidation_1-logloss:0.13681\n",
      "[434]\tvalidation_0-logloss:0.10065\tvalidation_1-logloss:0.13682\n",
      "[435]\tvalidation_0-logloss:0.10062\tvalidation_1-logloss:0.13683\n",
      "[436]\tvalidation_0-logloss:0.10052\tvalidation_1-logloss:0.13685\n",
      "[437]\tvalidation_0-logloss:0.10042\tvalidation_1-logloss:0.13681\n",
      "[438]\tvalidation_0-logloss:0.10036\tvalidation_1-logloss:0.13682\n",
      "[439]\tvalidation_0-logloss:0.10035\tvalidation_1-logloss:0.13683\n",
      "[440]\tvalidation_0-logloss:0.10027\tvalidation_1-logloss:0.13685\n",
      "[441]\tvalidation_0-logloss:0.10022\tvalidation_1-logloss:0.13686\n",
      "[442]\tvalidation_0-logloss:0.10012\tvalidation_1-logloss:0.13689\n",
      "[443]\tvalidation_0-logloss:0.09997\tvalidation_1-logloss:0.13687\n",
      "[444]\tvalidation_0-logloss:0.09986\tvalidation_1-logloss:0.13690\n",
      "[445]\tvalidation_0-logloss:0.09975\tvalidation_1-logloss:0.13690\n",
      "[446]\tvalidation_0-logloss:0.09971\tvalidation_1-logloss:0.13691\n",
      "[447]\tvalidation_0-logloss:0.09967\tvalidation_1-logloss:0.13691\n",
      "[448]\tvalidation_0-logloss:0.09955\tvalidation_1-logloss:0.13692\n",
      "[449]\tvalidation_0-logloss:0.09940\tvalidation_1-logloss:0.13693\n",
      "[450]\tvalidation_0-logloss:0.09927\tvalidation_1-logloss:0.13696\n",
      "[451]\tvalidation_0-logloss:0.09926\tvalidation_1-logloss:0.13696\n",
      "[452]\tvalidation_0-logloss:0.09925\tvalidation_1-logloss:0.13697\n",
      "[453]\tvalidation_0-logloss:0.09919\tvalidation_1-logloss:0.13698\n",
      "[454]\tvalidation_0-logloss:0.09911\tvalidation_1-logloss:0.13695\n",
      "[455]\tvalidation_0-logloss:0.09906\tvalidation_1-logloss:0.13696\n",
      "[456]\tvalidation_0-logloss:0.09900\tvalidation_1-logloss:0.13696\n",
      "[457]\tvalidation_0-logloss:0.09900\tvalidation_1-logloss:0.13696\n",
      "[458]\tvalidation_0-logloss:0.09898\tvalidation_1-logloss:0.13697\n",
      "[459]\tvalidation_0-logloss:0.09897\tvalidation_1-logloss:0.13697\n",
      "[460]\tvalidation_0-logloss:0.09883\tvalidation_1-logloss:0.13702\n",
      "[461]\tvalidation_0-logloss:0.09873\tvalidation_1-logloss:0.13704\n",
      "[462]\tvalidation_0-logloss:0.09865\tvalidation_1-logloss:0.13706\n",
      "[463]\tvalidation_0-logloss:0.09864\tvalidation_1-logloss:0.13707\n",
      "[464]\tvalidation_0-logloss:0.09863\tvalidation_1-logloss:0.13706\n",
      "[465]\tvalidation_0-logloss:0.09861\tvalidation_1-logloss:0.13708\n",
      "[466]\tvalidation_0-logloss:0.09858\tvalidation_1-logloss:0.13708\n",
      "[467]\tvalidation_0-logloss:0.09856\tvalidation_1-logloss:0.13710\n",
      "[468]\tvalidation_0-logloss:0.09852\tvalidation_1-logloss:0.13711\n",
      "[469]\tvalidation_0-logloss:0.09845\tvalidation_1-logloss:0.13712\n",
      "[470]\tvalidation_0-logloss:0.09843\tvalidation_1-logloss:0.13714\n",
      "[471]\tvalidation_0-logloss:0.09842\tvalidation_1-logloss:0.13714\n",
      "[472]\tvalidation_0-logloss:0.09841\tvalidation_1-logloss:0.13715\n",
      "[473]\tvalidation_0-logloss:0.09839\tvalidation_1-logloss:0.13717\n",
      "[474]\tvalidation_0-logloss:0.09837\tvalidation_1-logloss:0.13720\n",
      "[475]\tvalidation_0-logloss:0.09835\tvalidation_1-logloss:0.13719\n",
      "[476]\tvalidation_0-logloss:0.09834\tvalidation_1-logloss:0.13720\n",
      "[477]\tvalidation_0-logloss:0.09833\tvalidation_1-logloss:0.13720\n",
      "[478]\tvalidation_0-logloss:0.09832\tvalidation_1-logloss:0.13721\n",
      "[479]\tvalidation_0-logloss:0.09819\tvalidation_1-logloss:0.13724\n",
      "[480]\tvalidation_0-logloss:0.09815\tvalidation_1-logloss:0.13725\n",
      "[481]\tvalidation_0-logloss:0.09805\tvalidation_1-logloss:0.13728\n",
      "[482]\tvalidation_0-logloss:0.09804\tvalidation_1-logloss:0.13729\n",
      "[483]\tvalidation_0-logloss:0.09803\tvalidation_1-logloss:0.13731\n",
      "[484]\tvalidation_0-logloss:0.09802\tvalidation_1-logloss:0.13731\n",
      "[485]\tvalidation_0-logloss:0.09799\tvalidation_1-logloss:0.13731\n",
      "[486]\tvalidation_0-logloss:0.09796\tvalidation_1-logloss:0.13731\n",
      "[487]\tvalidation_0-logloss:0.09785\tvalidation_1-logloss:0.13730\n",
      "[488]\tvalidation_0-logloss:0.09784\tvalidation_1-logloss:0.13732\n",
      "[489]\tvalidation_0-logloss:0.09772\tvalidation_1-logloss:0.13734\n",
      "[490]\tvalidation_0-logloss:0.09770\tvalidation_1-logloss:0.13734\n",
      "[491]\tvalidation_0-logloss:0.09769\tvalidation_1-logloss:0.13734\n",
      "[492]\tvalidation_0-logloss:0.09767\tvalidation_1-logloss:0.13735\n",
      "[493]\tvalidation_0-logloss:0.09764\tvalidation_1-logloss:0.13736\n",
      "[494]\tvalidation_0-logloss:0.09763\tvalidation_1-logloss:0.13737\n",
      "[495]\tvalidation_0-logloss:0.09762\tvalidation_1-logloss:0.13738\n",
      "[496]\tvalidation_0-logloss:0.09761\tvalidation_1-logloss:0.13738\n",
      "[497]\tvalidation_0-logloss:0.09755\tvalidation_1-logloss:0.13739\n",
      "[498]\tvalidation_0-logloss:0.09747\tvalidation_1-logloss:0.13739\n",
      "[499]\tvalidation_0-logloss:0.09746\tvalidation_1-logloss:0.13739\n",
      "ROC AUC: 0.8385\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156, early_stopping_round=100)\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score)) # XGBoost ROC AUC: 0.8385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1d88ec2-68c9-4613-9bec-fc1e5962b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators=500, learning_rate=0.05, random_state=156, early_stopping_round=100 => ROC AUC: 0.8385\n",
    "# n_estimators=700, learning_rate=0.05, random_state=156, early_stopping_round=200 => ROC AUC: 0.8345\n",
    "# n_estimators=500, learning_rate=0.07, random_state=156, early_stopping_round=100 => ROC AUC: 0.8322\n",
    "# n_estimators=900, learning_rate=0.05, random_state=156, early_stopping_round=100 => ROC AUC: 0.8294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2369e1dd-a28f-4566-bf50-44e9bbb6d513",
   "metadata": {},
   "source": [
    "### XGBoost의 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b19fbf5a-4470-4f56-9ab7-fd312ecf6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.13.1)\n",
      "Requirement already satisfied: six in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (3.3)\n",
      "Requirement already satisfied: future in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (4.66.5)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (3.0.0)\n",
      "Requirement already satisfied: py4j in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from hyperopt) (0.10.9.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\juwonhee\\anaconda3\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install hyperopt\n",
    "from hyperopt import hp\n",
    "\n",
    "xgb_search_space = {'max_depth':hp.quniform('max_depth',5,15,1),\n",
    "                    'min_child_weight':hp.quniform('min_child_weight',1,6,1),\n",
    "                    'colsample_bytree':hp.uniform('colsample_bytree',0.5,0.95),\n",
    "                    'learning_rate':hp.uniform('learning_rate',0.01,0.2) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed7fe4-df2d-4d99-a799-58e4710d4c6e",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "745a05ca-a21b-4b66-a0e5-67db2984be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, \n",
    "                            max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                           early_stopping_rounds=30)\n",
    "\n",
    "    roc_auc_list = []\n",
    "\n",
    "    kf = KFold(n_splits=3)\n",
    "\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        \n",
    "        xgb_clf.fit(X_tr, y_tr,\n",
    "                    eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "                    verbose=False)\n",
    "        \n",
    "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    return -1 * np.mean(roc_auc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c4dc30d-5b5f-4d9c-bb51-2b557347a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [13:15<00:00, 15.91s/trial, best loss: -0.8387962102037628]\n",
      "best: {'colsample_bytree': 0.7896425601973851, 'learning_rate': 0.10113565387321358, 'max_depth': 5.0, 'min_child_weight': 5.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:',best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "830c2160-0240-4959-a1d8-9dce58e1a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.15884\tvalidation_1-logloss:0.16428\n",
      "[1]\tvalidation_0-logloss:0.15571\tvalidation_1-logloss:0.16123\n",
      "[2]\tvalidation_0-logloss:0.15342\tvalidation_1-logloss:0.15883\n",
      "[3]\tvalidation_0-logloss:0.14874\tvalidation_1-logloss:0.15420\n",
      "[4]\tvalidation_0-logloss:0.14723\tvalidation_1-logloss:0.15282\n",
      "[5]\tvalidation_0-logloss:0.14424\tvalidation_1-logloss:0.14992\n",
      "[6]\tvalidation_0-logloss:0.14175\tvalidation_1-logloss:0.14750\n",
      "[7]\tvalidation_0-logloss:0.13973\tvalidation_1-logloss:0.14556\n",
      "[8]\tvalidation_0-logloss:0.13868\tvalidation_1-logloss:0.14475\n",
      "[9]\tvalidation_0-logloss:0.13710\tvalidation_1-logloss:0.14326\n",
      "[10]\tvalidation_0-logloss:0.13635\tvalidation_1-logloss:0.14266\n",
      "[11]\tvalidation_0-logloss:0.13511\tvalidation_1-logloss:0.14154\n",
      "[12]\tvalidation_0-logloss:0.13403\tvalidation_1-logloss:0.14061\n",
      "[13]\tvalidation_0-logloss:0.13347\tvalidation_1-logloss:0.14019\n",
      "[14]\tvalidation_0-logloss:0.13258\tvalidation_1-logloss:0.13948\n",
      "[15]\tvalidation_0-logloss:0.13186\tvalidation_1-logloss:0.13881\n",
      "[16]\tvalidation_0-logloss:0.13115\tvalidation_1-logloss:0.13831\n",
      "[17]\tvalidation_0-logloss:0.13073\tvalidation_1-logloss:0.13803\n",
      "[18]\tvalidation_0-logloss:0.13018\tvalidation_1-logloss:0.13764\n",
      "[19]\tvalidation_0-logloss:0.12969\tvalidation_1-logloss:0.13727\n",
      "[20]\tvalidation_0-logloss:0.12928\tvalidation_1-logloss:0.13696\n",
      "[21]\tvalidation_0-logloss:0.12891\tvalidation_1-logloss:0.13682\n",
      "[22]\tvalidation_0-logloss:0.12848\tvalidation_1-logloss:0.13655\n",
      "[23]\tvalidation_0-logloss:0.12816\tvalidation_1-logloss:0.13630\n",
      "[24]\tvalidation_0-logloss:0.12783\tvalidation_1-logloss:0.13616\n",
      "[25]\tvalidation_0-logloss:0.12753\tvalidation_1-logloss:0.13600\n",
      "[26]\tvalidation_0-logloss:0.12724\tvalidation_1-logloss:0.13585\n",
      "[27]\tvalidation_0-logloss:0.12701\tvalidation_1-logloss:0.13569\n",
      "[28]\tvalidation_0-logloss:0.12683\tvalidation_1-logloss:0.13566\n",
      "[29]\tvalidation_0-logloss:0.12659\tvalidation_1-logloss:0.13552\n",
      "[30]\tvalidation_0-logloss:0.12640\tvalidation_1-logloss:0.13545\n",
      "[31]\tvalidation_0-logloss:0.12624\tvalidation_1-logloss:0.13537\n",
      "[32]\tvalidation_0-logloss:0.12604\tvalidation_1-logloss:0.13530\n",
      "[33]\tvalidation_0-logloss:0.12588\tvalidation_1-logloss:0.13522\n",
      "[34]\tvalidation_0-logloss:0.12572\tvalidation_1-logloss:0.13513\n",
      "[35]\tvalidation_0-logloss:0.12552\tvalidation_1-logloss:0.13510\n",
      "[36]\tvalidation_0-logloss:0.12537\tvalidation_1-logloss:0.13502\n",
      "[37]\tvalidation_0-logloss:0.12518\tvalidation_1-logloss:0.13500\n",
      "[38]\tvalidation_0-logloss:0.12505\tvalidation_1-logloss:0.13496\n",
      "[39]\tvalidation_0-logloss:0.12484\tvalidation_1-logloss:0.13493\n",
      "[40]\tvalidation_0-logloss:0.12470\tvalidation_1-logloss:0.13490\n",
      "[41]\tvalidation_0-logloss:0.12460\tvalidation_1-logloss:0.13491\n",
      "[42]\tvalidation_0-logloss:0.12446\tvalidation_1-logloss:0.13487\n",
      "[43]\tvalidation_0-logloss:0.12438\tvalidation_1-logloss:0.13483\n",
      "[44]\tvalidation_0-logloss:0.12412\tvalidation_1-logloss:0.13479\n",
      "[45]\tvalidation_0-logloss:0.12404\tvalidation_1-logloss:0.13478\n",
      "[46]\tvalidation_0-logloss:0.12390\tvalidation_1-logloss:0.13476\n",
      "[47]\tvalidation_0-logloss:0.12373\tvalidation_1-logloss:0.13476\n",
      "[48]\tvalidation_0-logloss:0.12359\tvalidation_1-logloss:0.13477\n",
      "[49]\tvalidation_0-logloss:0.12337\tvalidation_1-logloss:0.13476\n",
      "[50]\tvalidation_0-logloss:0.12312\tvalidation_1-logloss:0.13476\n",
      "[51]\tvalidation_0-logloss:0.12303\tvalidation_1-logloss:0.13476\n",
      "[52]\tvalidation_0-logloss:0.12295\tvalidation_1-logloss:0.13478\n",
      "[53]\tvalidation_0-logloss:0.12287\tvalidation_1-logloss:0.13477\n",
      "[54]\tvalidation_0-logloss:0.12275\tvalidation_1-logloss:0.13481\n",
      "[55]\tvalidation_0-logloss:0.12268\tvalidation_1-logloss:0.13481\n",
      "[56]\tvalidation_0-logloss:0.12247\tvalidation_1-logloss:0.13478\n",
      "[57]\tvalidation_0-logloss:0.12228\tvalidation_1-logloss:0.13478\n",
      "[58]\tvalidation_0-logloss:0.12224\tvalidation_1-logloss:0.13476\n",
      "[59]\tvalidation_0-logloss:0.12214\tvalidation_1-logloss:0.13478\n",
      "[60]\tvalidation_0-logloss:0.12208\tvalidation_1-logloss:0.13480\n",
      "[61]\tvalidation_0-logloss:0.12202\tvalidation_1-logloss:0.13479\n",
      "[62]\tvalidation_0-logloss:0.12194\tvalidation_1-logloss:0.13476\n",
      "[63]\tvalidation_0-logloss:0.12188\tvalidation_1-logloss:0.13478\n",
      "[64]\tvalidation_0-logloss:0.12170\tvalidation_1-logloss:0.13470\n",
      "[65]\tvalidation_0-logloss:0.12162\tvalidation_1-logloss:0.13472\n",
      "[66]\tvalidation_0-logloss:0.12156\tvalidation_1-logloss:0.13474\n",
      "[67]\tvalidation_0-logloss:0.12152\tvalidation_1-logloss:0.13472\n",
      "[68]\tvalidation_0-logloss:0.12147\tvalidation_1-logloss:0.13474\n",
      "[69]\tvalidation_0-logloss:0.12142\tvalidation_1-logloss:0.13478\n",
      "[70]\tvalidation_0-logloss:0.12134\tvalidation_1-logloss:0.13481\n",
      "[71]\tvalidation_0-logloss:0.12125\tvalidation_1-logloss:0.13479\n",
      "[72]\tvalidation_0-logloss:0.12111\tvalidation_1-logloss:0.13480\n",
      "[73]\tvalidation_0-logloss:0.12099\tvalidation_1-logloss:0.13477\n",
      "[74]\tvalidation_0-logloss:0.12091\tvalidation_1-logloss:0.13478\n",
      "[75]\tvalidation_0-logloss:0.12082\tvalidation_1-logloss:0.13477\n",
      "[76]\tvalidation_0-logloss:0.12072\tvalidation_1-logloss:0.13478\n",
      "[77]\tvalidation_0-logloss:0.12067\tvalidation_1-logloss:0.13480\n",
      "[78]\tvalidation_0-logloss:0.12048\tvalidation_1-logloss:0.13479\n",
      "[79]\tvalidation_0-logloss:0.12046\tvalidation_1-logloss:0.13479\n",
      "[80]\tvalidation_0-logloss:0.12031\tvalidation_1-logloss:0.13476\n",
      "[81]\tvalidation_0-logloss:0.12026\tvalidation_1-logloss:0.13480\n",
      "[82]\tvalidation_0-logloss:0.12022\tvalidation_1-logloss:0.13484\n",
      "[83]\tvalidation_0-logloss:0.12018\tvalidation_1-logloss:0.13487\n",
      "[84]\tvalidation_0-logloss:0.12014\tvalidation_1-logloss:0.13490\n",
      "[85]\tvalidation_0-logloss:0.12006\tvalidation_1-logloss:0.13491\n",
      "[86]\tvalidation_0-logloss:0.12002\tvalidation_1-logloss:0.13496\n",
      "[87]\tvalidation_0-logloss:0.11999\tvalidation_1-logloss:0.13499\n",
      "[88]\tvalidation_0-logloss:0.11995\tvalidation_1-logloss:0.13499\n",
      "[89]\tvalidation_0-logloss:0.11984\tvalidation_1-logloss:0.13502\n",
      "[90]\tvalidation_0-logloss:0.11979\tvalidation_1-logloss:0.13502\n",
      "[91]\tvalidation_0-logloss:0.11973\tvalidation_1-logloss:0.13502\n",
      "[92]\tvalidation_0-logloss:0.11966\tvalidation_1-logloss:0.13502\n",
      "[93]\tvalidation_0-logloss:0.11960\tvalidation_1-logloss:0.13505\n",
      "[94]\tvalidation_0-logloss:0.11957\tvalidation_1-logloss:0.13505\n",
      "[95]\tvalidation_0-logloss:0.11941\tvalidation_1-logloss:0.13503\n",
      "[96]\tvalidation_0-logloss:0.11918\tvalidation_1-logloss:0.13509\n",
      "[97]\tvalidation_0-logloss:0.11914\tvalidation_1-logloss:0.13510\n",
      "[98]\tvalidation_0-logloss:0.11905\tvalidation_1-logloss:0.13515\n",
      "[99]\tvalidation_0-logloss:0.11899\tvalidation_1-logloss:0.13518\n",
      "[100]\tvalidation_0-logloss:0.11894\tvalidation_1-logloss:0.13520\n",
      "[101]\tvalidation_0-logloss:0.11882\tvalidation_1-logloss:0.13520\n",
      "[102]\tvalidation_0-logloss:0.11879\tvalidation_1-logloss:0.13522\n",
      "[103]\tvalidation_0-logloss:0.11870\tvalidation_1-logloss:0.13524\n",
      "[104]\tvalidation_0-logloss:0.11866\tvalidation_1-logloss:0.13526\n",
      "[105]\tvalidation_0-logloss:0.11862\tvalidation_1-logloss:0.13530\n",
      "[106]\tvalidation_0-logloss:0.11848\tvalidation_1-logloss:0.13532\n",
      "[107]\tvalidation_0-logloss:0.11843\tvalidation_1-logloss:0.13535\n",
      "[108]\tvalidation_0-logloss:0.11837\tvalidation_1-logloss:0.13535\n",
      "[109]\tvalidation_0-logloss:0.11833\tvalidation_1-logloss:0.13537\n",
      "[110]\tvalidation_0-logloss:0.11827\tvalidation_1-logloss:0.13537\n",
      "[111]\tvalidation_0-logloss:0.11822\tvalidation_1-logloss:0.13538\n",
      "[112]\tvalidation_0-logloss:0.11809\tvalidation_1-logloss:0.13541\n",
      "[113]\tvalidation_0-logloss:0.11801\tvalidation_1-logloss:0.13538\n",
      "[114]\tvalidation_0-logloss:0.11796\tvalidation_1-logloss:0.13538\n",
      "[115]\tvalidation_0-logloss:0.11793\tvalidation_1-logloss:0.13538\n",
      "[116]\tvalidation_0-logloss:0.11790\tvalidation_1-logloss:0.13541\n",
      "[117]\tvalidation_0-logloss:0.11780\tvalidation_1-logloss:0.13543\n",
      "[118]\tvalidation_0-logloss:0.11766\tvalidation_1-logloss:0.13545\n",
      "[119]\tvalidation_0-logloss:0.11760\tvalidation_1-logloss:0.13547\n",
      "[120]\tvalidation_0-logloss:0.11758\tvalidation_1-logloss:0.13547\n",
      "[121]\tvalidation_0-logloss:0.11749\tvalidation_1-logloss:0.13548\n",
      "[122]\tvalidation_0-logloss:0.11746\tvalidation_1-logloss:0.13549\n",
      "[123]\tvalidation_0-logloss:0.11737\tvalidation_1-logloss:0.13554\n",
      "[124]\tvalidation_0-logloss:0.11736\tvalidation_1-logloss:0.13554\n",
      "[125]\tvalidation_0-logloss:0.11716\tvalidation_1-logloss:0.13556\n",
      "[126]\tvalidation_0-logloss:0.11708\tvalidation_1-logloss:0.13556\n",
      "[127]\tvalidation_0-logloss:0.11704\tvalidation_1-logloss:0.13556\n",
      "[128]\tvalidation_0-logloss:0.11697\tvalidation_1-logloss:0.13554\n",
      "[129]\tvalidation_0-logloss:0.11690\tvalidation_1-logloss:0.13557\n",
      "[130]\tvalidation_0-logloss:0.11675\tvalidation_1-logloss:0.13559\n",
      "[131]\tvalidation_0-logloss:0.11664\tvalidation_1-logloss:0.13563\n",
      "[132]\tvalidation_0-logloss:0.11647\tvalidation_1-logloss:0.13563\n",
      "[133]\tvalidation_0-logloss:0.11644\tvalidation_1-logloss:0.13565\n",
      "[134]\tvalidation_0-logloss:0.11641\tvalidation_1-logloss:0.13567\n",
      "[135]\tvalidation_0-logloss:0.11637\tvalidation_1-logloss:0.13571\n",
      "[136]\tvalidation_0-logloss:0.11632\tvalidation_1-logloss:0.13573\n",
      "[137]\tvalidation_0-logloss:0.11630\tvalidation_1-logloss:0.13570\n",
      "[138]\tvalidation_0-logloss:0.11624\tvalidation_1-logloss:0.13569\n",
      "[139]\tvalidation_0-logloss:0.11621\tvalidation_1-logloss:0.13571\n",
      "[140]\tvalidation_0-logloss:0.11618\tvalidation_1-logloss:0.13574\n",
      "[141]\tvalidation_0-logloss:0.11612\tvalidation_1-logloss:0.13578\n",
      "[142]\tvalidation_0-logloss:0.11602\tvalidation_1-logloss:0.13577\n",
      "[143]\tvalidation_0-logloss:0.11589\tvalidation_1-logloss:0.13574\n",
      "[144]\tvalidation_0-logloss:0.11582\tvalidation_1-logloss:0.13575\n",
      "[145]\tvalidation_0-logloss:0.11578\tvalidation_1-logloss:0.13578\n",
      "[146]\tvalidation_0-logloss:0.11573\tvalidation_1-logloss:0.13577\n",
      "[147]\tvalidation_0-logloss:0.11566\tvalidation_1-logloss:0.13580\n",
      "[148]\tvalidation_0-logloss:0.11555\tvalidation_1-logloss:0.13583\n",
      "[149]\tvalidation_0-logloss:0.11547\tvalidation_1-logloss:0.13583\n",
      "[150]\tvalidation_0-logloss:0.11544\tvalidation_1-logloss:0.13584\n",
      "[151]\tvalidation_0-logloss:0.11531\tvalidation_1-logloss:0.13587\n",
      "[152]\tvalidation_0-logloss:0.11530\tvalidation_1-logloss:0.13588\n",
      "[153]\tvalidation_0-logloss:0.11517\tvalidation_1-logloss:0.13590\n",
      "[154]\tvalidation_0-logloss:0.11513\tvalidation_1-logloss:0.13591\n",
      "[155]\tvalidation_0-logloss:0.11505\tvalidation_1-logloss:0.13593\n",
      "[156]\tvalidation_0-logloss:0.11498\tvalidation_1-logloss:0.13596\n",
      "[157]\tvalidation_0-logloss:0.11485\tvalidation_1-logloss:0.13600\n",
      "[158]\tvalidation_0-logloss:0.11483\tvalidation_1-logloss:0.13599\n",
      "[159]\tvalidation_0-logloss:0.11477\tvalidation_1-logloss:0.13599\n",
      "[160]\tvalidation_0-logloss:0.11476\tvalidation_1-logloss:0.13603\n",
      "[161]\tvalidation_0-logloss:0.11473\tvalidation_1-logloss:0.13604\n",
      "[162]\tvalidation_0-logloss:0.11465\tvalidation_1-logloss:0.13606\n",
      "[163]\tvalidation_0-logloss:0.11461\tvalidation_1-logloss:0.13611\n",
      "[164]\tvalidation_0-logloss:0.11459\tvalidation_1-logloss:0.13610\n",
      "ROC AUC: 0.8424\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=round(best['learning_rate'],5),\n",
    "                        max_depth = int(best['max_depth']),\n",
    "                        min_child_weight = int(best['min_child_weight']),\n",
    "                        colsample_bytree=round(best['colsample_bytree'],5),\n",
    "                        early_stopping_rounds=100\n",
    "                       )\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr,\n",
    "            eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score)) # 하이퍼파라미터 튜닝 ROC AUC: 0.8424"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b6981-55f3-4e15-999f-db59b5019bb0",
   "metadata": {},
   "source": [
    "### 결과\n",
    "XGBoost ROC AUC: 0.8385  \n",
    "하이퍼파라미터 튜닝 ROC AUC: 0.8424  \n",
    "  \n",
    "튜닝 이후 개선되었다.\n",
    "단, XGBoost가 GBM보다는 빠르지만 아무래도 GBM을 기반으로 하기 때문에 수행 시간이 상당히 많이 요구된다.  \n",
    "앙상블 계열 알고리즘에서 하이퍼 파라미터 튜닝으로 성능 수치 개선이 급격히 되는 경우는 많지 않다.  \n",
    "\n",
    "튜닝된 모델에서 각 피처의 중요도를 피처 중요도 그래프로 표현 -> xgboost 모듈의 plot_importance() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "183da77e-b798-4a80-8e63-e881524127e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "plot_importance(xgb_clf, ax=ax, max_num_features=20, height=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c95f58-40cb-40fe-9764-25da583f1ca3",
   "metadata": {},
   "source": [
    "XGBoost 예측 성능을 좌우하는 중요 피처 : var38, var15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a712fa9-93a2-42cd-8dfa-2a075fb505c6",
   "metadata": {},
   "source": [
    "## LightGBM 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abebcf-38b4-40c5-bea7-13c3cee0d107",
   "metadata": {},
   "source": [
    "### LightGBM모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ee97f6e-6c38-472a-aabe-25332a299eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13234\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 241\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.10964\tvalid_1's binary_logloss: 0.136462\n",
      "ROC AUC: 0.838887\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100)\n",
    "\n",
    "eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_Score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:4f}'.format(lgbm_roc_Score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337adf2-8524-4cd8-b2aa-f58cd97c35cd",
   "metadata": {},
   "source": [
    "### LightGBM의 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f0afb15-f342-4dc1-9f5f-bf9a49819f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves':hp.quniform('num_leaves',32,64,1),\n",
    "                     'max_depth': hp.quniform('max_depth',100,160,1),\n",
    "                    'min_child_samples':hp.quniform('min_child_samples',60,100,1),\n",
    "                    'subsample':hp.uniform('subsample',0.7,1),\n",
    "                    'learning_rate':hp.uniform('learning_rate',0.01,0.2)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "93517862-3d51-4483-b837-a0a84c5d077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                              num_leaves=int(search_space['num_leaves']),\n",
    "                              max_depth=int(search_space['max_depth']),\n",
    "                              min_child_samples=int(search_space['min_child_samples']),\n",
    "                              subsample=search_space['subsample'],\n",
    "                              learning_rate=search_space['learning_rate'],\n",
    "                             early_stopping_rounds=30)\n",
    "    roc_auc_list = []\n",
    "    kf = KFold(n_splits=3)\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_val, y_val)])\n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:,1])\n",
    "        roc_auc_list.append(score)\n",
    "    return -1 * np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8a22144b-3aba-4264-9196-540379a23a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056695 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[99]\ttraining's binary_logloss: 0.121691\tvalid_1's binary_logloss: 0.135854\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043421 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.123806\tvalid_1's binary_logloss: 0.13102\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047531 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.121345\tvalid_1's binary_logloss: 0.136434\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045704 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's binary_logloss: 0.116101\tvalid_1's binary_logloss: 0.13651\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050242 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's binary_logloss: 0.115144\tvalid_1's binary_logloss: 0.131217\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045515 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's binary_logloss: 0.114807\tvalid_1's binary_logloss: 0.137799\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043425 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's binary_logloss: 0.117842\tvalid_1's binary_logloss: 0.13612\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080120 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's binary_logloss: 0.116124\tvalid_1's binary_logloss: 0.130594\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074874 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[45]\ttraining's binary_logloss: 0.115344\tvalid_1's binary_logloss: 0.136679\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051772 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's binary_logloss: 0.110829\tvalid_1's binary_logloss: 0.136072\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051805 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's binary_logloss: 0.108961\tvalid_1's binary_logloss: 0.130846\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.183018 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's binary_logloss: 0.110318\tvalid_1's binary_logloss: 0.137738\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136256 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's binary_logloss: 0.115347\tvalid_1's binary_logloss: 0.135605\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198498 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[55]\ttraining's binary_logloss: 0.115128\tvalid_1's binary_logloss: 0.130766\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042898 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's binary_logloss: 0.114029\tvalid_1's binary_logloss: 0.136655\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040933 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.127637\tvalid_1's binary_logloss: 0.137831\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053152 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.129898\tvalid_1's binary_logloss: 0.133066\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043468 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.127136\tvalid_1's binary_logloss: 0.138892\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051527 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's binary_logloss: 0.120387\tvalid_1's binary_logloss: 0.136333\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054867 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's binary_logloss: 0.118736\tvalid_1's binary_logloss: 0.131262\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040489 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's binary_logloss: 0.116468\tvalid_1's binary_logloss: 0.137155\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053806 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12885                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's binary_logloss: 0.115785\tvalid_1's binary_logloss: 0.136488\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053809 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.114888\tvalid_1's binary_logloss: 0.131395\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049046 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's binary_logloss: 0.113891\tvalid_1's binary_logloss: 0.138015\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043083 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's binary_logloss: 0.119098\tvalid_1's binary_logloss: 0.136082\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058902 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's binary_logloss: 0.118696\tvalid_1's binary_logloss: 0.131068\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050264 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's binary_logloss: 0.116749\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050544 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37]\ttraining's binary_logloss: 0.117245\tvalid_1's binary_logloss: 0.136033\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047528 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[46]\ttraining's binary_logloss: 0.115521\tvalid_1's binary_logloss: 0.130554\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044478 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's binary_logloss: 0.116854\tvalid_1's binary_logloss: 0.136736\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053858 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's binary_logloss: 0.114779\tvalid_1's binary_logloss: 0.136755\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063353 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's binary_logloss: 0.115313\tvalid_1's binary_logloss: 0.133237\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062769 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's binary_logloss: 0.112274\tvalid_1's binary_logloss: 0.139062\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057436 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[44]\ttraining's binary_logloss: 0.114367\tvalid_1's binary_logloss: 0.136203\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061779 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[53]\ttraining's binary_logloss: 0.113074\tvalid_1's binary_logloss: 0.131037\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049066 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's binary_logloss: 0.111096\tvalid_1's binary_logloss: 0.137228\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050009 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's binary_logloss: 0.11902\tvalid_1's binary_logloss: 0.136321\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054887 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13050                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's binary_logloss: 0.11568\tvalid_1's binary_logloss: 0.131373\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066466 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.113956\tvalid_1's binary_logloss: 0.137568\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053714 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[64]\ttraining's binary_logloss: 0.113833\tvalid_1's binary_logloss: 0.13584\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055418 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13046                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[76]\ttraining's binary_logloss: 0.113411\tvalid_1's binary_logloss: 0.130684\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045778 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[75]\ttraining's binary_logloss: 0.11079\tvalid_1's binary_logloss: 0.13635\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039787 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's binary_logloss: 0.119835\tvalid_1's binary_logloss: 0.135834\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032758 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's binary_logloss: 0.117984\tvalid_1's binary_logloss: 0.131018\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034210 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's binary_logloss: 0.114383\tvalid_1's binary_logloss: 0.136812\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040838 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[46]\ttraining's binary_logloss: 0.114433\tvalid_1's binary_logloss: 0.135977\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041065 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[57]\ttraining's binary_logloss: 0.112461\tvalid_1's binary_logloss: 0.131242\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031253 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's binary_logloss: 0.111934\tvalid_1's binary_logloss: 0.137242\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034110 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12835                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.120091\tvalid_1's binary_logloss: 0.135824\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039834 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.12218\tvalid_1's binary_logloss: 0.13083\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034744 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12863                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.119522\tvalid_1's binary_logloss: 0.136618\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032790 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's binary_logloss: 0.116893\tvalid_1's binary_logloss: 0.136357\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047604 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's binary_logloss: 0.113216\tvalid_1's binary_logloss: 0.13115\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030615 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's binary_logloss: 0.110917\tvalid_1's binary_logloss: 0.136891\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033180 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.114527\tvalid_1's binary_logloss: 0.136277\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035959 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's binary_logloss: 0.113994\tvalid_1's binary_logloss: 0.131827\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040782 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.113791\tvalid_1's binary_logloss: 0.137537\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041264 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.119715\tvalid_1's binary_logloss: 0.135597\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042374 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.121795\tvalid_1's binary_logloss: 0.130833\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038678 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.119143\tvalid_1's binary_logloss: 0.136485\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037730 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.115666\tvalid_1's binary_logloss: 0.135727\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042617 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[98]\ttraining's binary_logloss: 0.118088\tvalid_1's binary_logloss: 0.130656\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042029 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[95]\ttraining's binary_logloss: 0.115823\tvalid_1's binary_logloss: 0.136543\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035668 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12926                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37]\ttraining's binary_logloss: 0.115388\tvalid_1's binary_logloss: 0.135942\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038404 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's binary_logloss: 0.115476\tvalid_1's binary_logloss: 0.130922\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043507 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's binary_logloss: 0.113368\tvalid_1's binary_logloss: 0.13644\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046057 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.128787\tvalid_1's binary_logloss: 0.137803\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046187 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.131041\tvalid_1's binary_logloss: 0.133108\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055032 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.128267\tvalid_1's binary_logloss: 0.138809\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069118 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.117721\tvalid_1's binary_logloss: 0.135749\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039102 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.1202\tvalid_1's binary_logloss: 0.130426\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050550 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[99]\ttraining's binary_logloss: 0.117598\tvalid_1's binary_logloss: 0.135991\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039846 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's binary_logloss: 0.118799\tvalid_1's binary_logloss: 0.135841\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036808 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43]\ttraining's binary_logloss: 0.116214\tvalid_1's binary_logloss: 0.13057\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046204 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's binary_logloss: 0.118269\tvalid_1's binary_logloss: 0.136548\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049657 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[80]\ttraining's binary_logloss: 0.120175\tvalid_1's binary_logloss: 0.135615\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037229 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.119917\tvalid_1's binary_logloss: 0.130481\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043997 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[97]\ttraining's binary_logloss: 0.117594\tvalid_1's binary_logloss: 0.135984\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034389 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.132023\tvalid_1's binary_logloss: 0.140025\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035571 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.134325\tvalid_1's binary_logloss: 0.135128\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037272 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.131493\tvalid_1's binary_logloss: 0.141144\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036526 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's binary_logloss: 0.115089\tvalid_1's binary_logloss: 0.135956\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039463 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's binary_logloss: 0.115673\tvalid_1's binary_logloss: 0.130635\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033929 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's binary_logloss: 0.115611\tvalid_1's binary_logloss: 0.13686\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028833 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[92]\ttraining's binary_logloss: 0.115813\tvalid_1's binary_logloss: 0.135322\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034724 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[92]\ttraining's binary_logloss: 0.117963\tvalid_1's binary_logloss: 0.130349\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038153 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[94]\ttraining's binary_logloss: 0.114921\tvalid_1's binary_logloss: 0.136087\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043490 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[86]\ttraining's binary_logloss: 0.116619\tvalid_1's binary_logloss: 0.135645\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038892 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[92]\ttraining's binary_logloss: 0.117938\tvalid_1's binary_logloss: 0.130448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034814 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[77]\ttraining's binary_logloss: 0.117748\tvalid_1's binary_logloss: 0.136235\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040026 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\ttraining's binary_logloss: 0.11633\tvalid_1's binary_logloss: 0.135504\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039581 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[47]\ttraining's binary_logloss: 0.120421\tvalid_1's binary_logloss: 0.130419\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038590 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\ttraining's binary_logloss: 0.115794\tvalid_1's binary_logloss: 0.135859\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036909 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's binary_logloss: 0.116404\tvalid_1's binary_logloss: 0.135806\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033832 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's binary_logloss: 0.118006\tvalid_1's binary_logloss: 0.13048\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038970 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[53]\ttraining's binary_logloss: 0.114515\tvalid_1's binary_logloss: 0.13597\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034999 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\ttraining's binary_logloss: 0.117342\tvalid_1's binary_logloss: 0.135969\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034590 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's binary_logloss: 0.113141\tvalid_1's binary_logloss: 0.131089\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035208 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's binary_logloss: 0.115371\tvalid_1's binary_logloss: 0.136859\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039414 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's binary_logloss: 0.114195\tvalid_1's binary_logloss: 0.136286\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035842 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's binary_logloss: 0.109021\tvalid_1's binary_logloss: 0.131129\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034338 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's binary_logloss: 0.113768\tvalid_1's binary_logloss: 0.137725\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038881 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's binary_logloss: 0.120097\tvalid_1's binary_logloss: 0.135686\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035365 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's binary_logloss: 0.119396\tvalid_1's binary_logloss: 0.130514\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031097 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's binary_logloss: 0.116378\tvalid_1's binary_logloss: 0.1362\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040268 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[67]\ttraining's binary_logloss: 0.11705\tvalid_1's binary_logloss: 0.1355\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044532 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[79]\ttraining's binary_logloss: 0.117347\tvalid_1's binary_logloss: 0.130237\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042333 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[76]\ttraining's binary_logloss: 0.115092\tvalid_1's binary_logloss: 0.136329\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045392 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's binary_logloss: 0.114995\tvalid_1's binary_logloss: 0.136039\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040942 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's binary_logloss: 0.11569\tvalid_1's binary_logloss: 0.13063\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038919 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's binary_logloss: 0.113835\tvalid_1's binary_logloss: 0.13665\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048967 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's binary_logloss: 0.11721\tvalid_1's binary_logloss: 0.135984\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043403 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\ttraining's binary_logloss: 0.114459\tvalid_1's binary_logloss: 0.130701\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.066345 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's binary_logloss: 0.115871\tvalid_1's binary_logloss: 0.136668\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049381 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's binary_logloss: 0.120348\tvalid_1's binary_logloss: 0.136155\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060237 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's binary_logloss: 0.119451\tvalid_1's binary_logloss: 0.131012\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042052 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's binary_logloss: 0.11645\tvalid_1's binary_logloss: 0.136451\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044971 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35]\ttraining's binary_logloss: 0.12009\tvalid_1's binary_logloss: 0.135675\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040931 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[49]\ttraining's binary_logloss: 0.118193\tvalid_1's binary_logloss: 0.130602\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039766 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's binary_logloss: 0.11623\tvalid_1's binary_logloss: 0.136153\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038099 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[52]\ttraining's binary_logloss: 0.116738\tvalid_1's binary_logloss: 0.135853\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040453 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[59]\ttraining's binary_logloss: 0.117418\tvalid_1's binary_logloss: 0.130448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033850 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[64]\ttraining's binary_logloss: 0.113352\tvalid_1's binary_logloss: 0.136288\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045995 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's binary_logloss: 0.116344\tvalid_1's binary_logloss: 0.136167\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043586 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35]\ttraining's binary_logloss: 0.113436\tvalid_1's binary_logloss: 0.131078\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033097 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's binary_logloss: 0.113935\tvalid_1's binary_logloss: 0.137141\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041476 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[63]\ttraining's binary_logloss: 0.112933\tvalid_1's binary_logloss: 0.136188\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043117 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[62]\ttraining's binary_logloss: 0.115172\tvalid_1's binary_logloss: 0.130748\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044934 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\ttraining's binary_logloss: 0.114785\tvalid_1's binary_logloss: 0.136832\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042875 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's binary_logloss: 0.117312\tvalid_1's binary_logloss: 0.135902\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082318 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.118173\tvalid_1's binary_logloss: 0.131307\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035501 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.115554\tvalid_1's binary_logloss: 0.137295\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039369 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.121907\tvalid_1's binary_logloss: 0.135965\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037500 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.124035\tvalid_1's binary_logloss: 0.131212\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041708 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.121394\tvalid_1's binary_logloss: 0.136876\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045613 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's binary_logloss: 0.11663\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049642 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's binary_logloss: 0.117802\tvalid_1's binary_logloss: 0.131163\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040932 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's binary_logloss: 0.109973\tvalid_1's binary_logloss: 0.13719\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038652 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[45]\ttraining's binary_logloss: 0.119207\tvalid_1's binary_logloss: 0.135473\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037969 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[55]\ttraining's binary_logloss: 0.119242\tvalid_1's binary_logloss: 0.130134\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042557 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[55]\ttraining's binary_logloss: 0.116569\tvalid_1's binary_logloss: 0.136171\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044267 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's binary_logloss: 0.114617\tvalid_1's binary_logloss: 0.136351\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048231 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's binary_logloss: 0.112433\tvalid_1's binary_logloss: 0.131448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037127 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's binary_logloss: 0.112794\tvalid_1's binary_logloss: 0.137877\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036649 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's binary_logloss: 0.114476\tvalid_1's binary_logloss: 0.137269\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046845 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's binary_logloss: 0.117329\tvalid_1's binary_logloss: 0.132223\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044572 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's binary_logloss: 0.118661\tvalid_1's binary_logloss: 0.138344\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042932 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872                                        \n",
      "[LightGBM] [Info] Start training from score -3.205872                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.124109\tvalid_1's binary_logloss: 0.136673\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041677 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281                                        \n",
      "[LightGBM] [Info] Start training from score -3.186281                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.126412\tvalid_1's binary_logloss: 0.131761\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044389 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465                                        \n",
      "[LightGBM] [Info] Start training from score -3.218465                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's binary_logloss: 0.123614\tvalid_1's binary_logloss: 0.137451\n",
      "100%|████████████████████████████████████████████████| 50/50 [08:47<00:00, 10.56s/trial, best loss: -0.835966039415564]\n",
      "best: {'learning_rate': 0.07283348800335702, 'max_depth': 133.0, 'min_child_samples': 89.0, 'num_leaves': 32.0, 'subsample': 0.7011491391896255}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, space=lgbm_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials,\n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:',best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11191b6a-bf42-41b1-9626-b244daf1a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.115794\tvalid_1's binary_logloss: 0.135859\n",
      "ROC AUC: 0.8424\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),\n",
    "                          max_depth=int(best['max_depth']),\n",
    "                          min_child_samples=int(best['min_child_samples']),\n",
    "                          subsample=round(best['subsample'],5),\n",
    "                          learning_rate=round(best['learning_rate'],5),\n",
    "                          early_stopping_rounds=100\n",
    "                         )\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr),(X_val, y_val)])\n",
    "lgbm_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec17256-fd12-4e73-b184-667dd504c820",
   "metadata": {},
   "source": [
    "### 결과\n",
    "LightGBM ROC AUC: 0.838887  \n",
    "LightGBM 하이퍼파라미터 튜닝 ROC AUC: 0.8424"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680c05a-8a51-46ce-b1ee-461167f50816",
   "metadata": {},
   "source": [
    "- XGBoost ROC AUC: 0.8385\n",
    "- XGBoost 하이퍼파라미터 튜닝 ROC AUC: 0.8424\n",
    "- LightGBM ROC AUC: 0.8388\n",
    "- LightGBM 하이퍼파라미터 튜닝 ROC AUC: 0.8424  \n",
    "=> LightGBM이 가장 성능이 좋았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef568a4-d681-49aa-b0e7-3322c6e9728e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
